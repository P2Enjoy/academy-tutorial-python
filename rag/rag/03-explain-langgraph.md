# **LangGraph : Compr√©hension approfondie et usages avanc√©s**

LangGraph est un outil permettant de mod√©liser des flux de travail complexes utilisant des graphes d'agents. Un graphe est compos√© de n≈ìuds (actions) reli√©s par des ar√™tes (transitions), structurant ainsi clairement l'ex√©cution dynamique des workflows intelligents, tels que les chatbots, les assistants virtuels ou les syst√®mes d√©cisionnels intelligents.  

## **1. Introduction et motivations**

### 1.1. Pourquoi LangGraph ?

LangGraph est con√ßu pour r√©pondre aux besoins croissants en mati√®re d‚Äôapplications pilot√©es par des **LLMs** (Large Language Models). Les LLMs rendent possible l‚Äôint√©gration d‚Äô¬´ intelligence ¬ª dans une nouvelle g√©n√©ration d‚Äôapplications (chatbots, syst√®mes d√©cisionnels avanc√©s, agents autonomes, etc.). Deux grandes approches se d√©gagent :

1. **Approche ‚Äúworkflow‚Äù** : o√π l‚Äôon d√©finit un encha√Ænement de t√¢ches pr√©√©tabli (scaffolding) autour d‚Äôappels LLM. Le LLM peut s‚Äôins√©rer comme une brique d‚Äôintelligence au sein de ce flux de travail.
2. **Approche ‚Äúagentique‚Äù** : o√π le LLM prend en main la logique de contr√¥le du flux (planning, appels √† des outils, d√©cisions d‚Äôinterruption ou de reprise), permettant au mod√®le d‚Äôagir et de raisonner de mani√®re plus autonome.

Dans les deux cas, LangGraph se d√©marque par :

- **La persistance** (persistence) : m√©morisation de l‚Äô√©tat pour des ex√©cutions s√©quentielles, pour la validation humaine (human-in-the-loop) et pour le suivi de longues conversations.
- **Le streaming** : diffusion en temps r√©el des √©tats et des √©v√©nements (par exemple, flux de tokens issus d‚Äôun LLM).
- **La facilit√© de d√©bogage et de d√©ploiement** : gr√¢ce notamment √† LangGraph Platform et Studio, un environnement IDE/visualisation d√©di√©.

### 1.2. Applications LLM et Agent Workflow

Les LLMs permettent d√©sormais de construire non seulement des workflows statiques, mais aussi des **agents autonomes** capables de :

- Se doter d‚Äôune m√©moire de conversation.
- Planifier des actions via des outils (APIs, bases de donn√©es, etc.).
- Analyser et adapter leurs actions en temps r√©el.

LangGraph fournit une **infrastructure de bas niveau** pour soutenir ce type de workflows, qu‚Äôils soient strictement s√©quentiels ou largement autonomes.

### 1.3. Ce que fournit LangGraph

LangGraph offre trois b√©n√©fices centraux :

1. **Persistance**  
   - **M√©moire** : conservation des √©tats (historique de conversation, variables interm√©diaires, etc.).  
   - **Human-in-the-loop** : possibilit√© d‚Äôinterrompre l‚Äôex√©cution et de la reprendre ult√©rieurement apr√®s intervention humaine.

2. **Streaming**  
   - Remont√©e en continu d‚Äô√©v√©nements : logs, feedback d‚Äôoutils, ou encore tokens d‚Äôun LLM pour affichage progressif.

3. **D√©bogage et d√©ploiement**  
   - Int√©gration avec LangGraph Platform pour la **visualisation**, la **mise en production** et le **monitoring** de vos workflows ou agents.

---

## **2. Principes g√©n√©raux de LangGraph**

LangGraph mod√©lise les **workflows** (ou ¬´ graphes d‚Äôagents ¬ª) comme un **graphe**. Les composants fondamentaux sont :

1. **L‚Äô√âtat (State)** : la structure de donn√©es globale (snapshot) √† un instant T.  
2. **Les N≈ìuds (Nodes)** : des fonctions Python effectuant une op√©ration (calcul, appel LLM, requ√™te API, etc.).  
3. **Les Ar√™tes (Edges)** : d√©finissent la transition (logique de contr√¥le) entre ces n≈ìuds.

### 2.1. L‚Äô√âtat (State)

L‚Äô√âtat d√©finit le **sch√©ma** des donn√©es manipul√©es par le graphe. Il peut √™tre :

- Un **TypedDict** simple,
- Un **mod√®le Pydantic** (qui offre validations et valeurs par d√©faut),
- Ou plusieurs sch√©mas combin√©s (ex. : sch√©ma d‚Äôentr√©e, sch√©ma de sortie, sch√©ma interne).

> **Exemple minimal**  
> ```python
> from typing_extensions import TypedDict
>
> # √âtat d'entr√©e du graphe
> class InputState(TypedDict):
>     user_input: str  # Entr√©e utilisateur initiale
>
> # √âtat de sortie du graphe
> class OutputState(TypedDict):
>     graph_output: str  # R√©sultat final produit par le graphe
> ```

**Multi-sch√©mas** : Dans certains cas, vous pouvez s√©parer l‚Äô√©tat d‚Äôentr√©e, de sortie et un √©tat interne (pour stocker des variables temporaires).

> **Exemple plus avanc√© :**  
> ```python
> class InputState(TypedDict):
>     user_input: str
>
> class OutputState(TypedDict):
>     graph_output: str
>
> class OverallState(TypedDict):
>     foo: str
>     user_input: str
>     graph_output: str
>
> class PrivateState(TypedDict):
>     bar: str
>
> def node_1(state: InputState) -> OverallState:
>     return {"foo": state["user_input"] + " name"}
>
> def node_2(state: OverallState) -> PrivateState:
>     return {"bar": state["foo"] + " is"}
>
> def node_3(state: PrivateState) -> OutputState:
>     return {"graph_output": state["bar"] + " Lance"}
>
> from langgraph.graph import StateGraph, START, END
>
> builder = StateGraph(OverallState, input=InputState, output=OutputState)
> builder.add_node("node_1", node_1)
> builder.add_node("node_2", node_2)
> builder.add_node("node_3", node_3)
> builder.add_edge(START, "node_1")
> builder.add_edge("node_1", "node_2")
> builder.add_edge("node_2", "node_3")
> builder.add_edge("node_3", END)
>
> graph = builder.compile()
> graph.invoke({"user_input": "My"})
> # R√©sultat : {'graph_output': 'My name is Lance'}
> ```

### 2.2. Les N≈ìuds (Nodes)

Les n≈ìuds sont des fonctions Python synchrones ou asynchrones qui re√ßoivent l‚Äô√©tat et renvoient soit :

- Un simple **dictionnaire** d‚Äôupdates (mises √† jour partielles de l‚Äô√©tat),
- Ou un **Command** d√©crivant √† la fois la mise √† jour de l‚Äô√©tat et la route suivante (voir plus loin).

> **Exemple simple :**  
> ```python
> def node_1(state: InputState) -> dict:
>     return {"foo": state["user_input"] + " name"}
> ```

> **Exemple de n≈ìud renvoyant un `Command`**  
> ```python
> from langgraph.graph import Command
> from typing import Literal
>
> def my_node(state: dict) -> Command[Literal["my_other_node"]]:
>     return Command(
>         update={"foo": "bar"},
>         goto="my_other_node"   # indique le prochain n≈ìud
>     )
> ```

Si vous n‚Äôindiquez pas de nom lors de l‚Äôajout du n≈ìud dans le graphe (`builder.add_node(...)`), le nom de la fonction est utilis√© par d√©faut.

### 2.3. Les Ar√™tes (Edges)

Les ar√™tes d√©finissent la **logique de transition** :

- **Ar√™te normale** : `graph.add_edge("node_a", "node_b")`
- **Ar√™te conditionnelle** : `graph.add_conditional_edges("node_a", routing_function, mapping)`
- **Le pseudo-n≈ìud `START`** d√©signe l‚Äôentr√©e du graphe (r√©ception des donn√©es initiales).
- **Le pseudo-n≈ìud `END`** d√©signe la sortie du graphe (fin d‚Äôex√©cution).

> **Exemple d‚Äôajout d‚Äôune ar√™te simple :**  
> ```python
> from langgraph.graph import StateGraph, START
>
> builder = StateGraph(dict)
> builder.add_node("node_1", node_1)
> builder.add_edge(START, "node_1")
> ```

Pour des routes complexes, on peut utiliser des **fonctions de routage** :

```python
def routing_function(state: dict):
    return "node_b" if state.get("foo") == "bar" else "node_c"

builder.add_conditional_edges("node_a", routing_function)
```

---

## **3. M√©canisme d‚Äôex√©cution du graphe**

LangGraph utilise un algorithme bas√© sur le **passage de messages** (inspir√© du mod√®le Pregel de Google).

1. **Activation** : Un n≈ìud devient actif en recevant un message (ou au d√©part, via `START`).  
2. **Ex√©cution** : Il traite l‚Äô√©tat, g√©n√®re des mises √† jour (et √©ventuellement un ordre de route).  
3. **Transmission** : Les mises √† jour sont transmises aux n≈ìuds suivant(s).  
4. **Inactivit√©** : Si un n≈ìud ne re√ßoit plus de messages, il reste inactif. L‚Äôex√©cution s‚Äôarr√™te quand plus aucun n≈ìud n‚Äôest actif.

### 3.1. Super-pas (Super-steps)

- Un **super-pas** est une it√©ration lors de laquelle plusieurs n≈ìuds s‚Äôex√©cutent en parall√®le.  
- Une fois ces n≈ìuds termin√©s, ils envoient leurs messages et activent d‚Äô√©ventuels n≈ìuds pour le super-pas suivant.  
- L‚Äôex√©cution termine quand tous les n≈ìuds sont inactifs (plus de messages en transit).

---

## **4. Persistence : gestion de l‚Äô√©tat, human-in-the-loop**

### 4.1. Checkpointers et Persistance

LangGraph propose un m√©canisme de **persistence** (via des ‚Äúcheckpointers‚Äù) qui :

- Conserve l‚Äô√©volution de l‚Äô√©tat √† chaque super-pas.  
- Autorise l‚Äô**interruption** (pour validation humaine ou autre) et la **reprise**.  
- Facilite le d√©bogage ou le rollback √† un √©tat ant√©rieur.

### 4.2. Human-in-the-loop (Interrupt)

Vous pouvez volontairement interrompre l‚Äôex√©cution avec la fonction `interrupt` pour demander une **validation utilisateur** :

```python
from langgraph.types import interrupt

def human_approval_node(state: dict):
    answer = interrupt({"question": "is it ok to continue?"})
    return {"decision": f"User said: {answer}"}
```

La reprise du graphe s‚Äôeffectue en fournissant la r√©ponse humaine dans l‚Äô√©tat, sous forme d‚Äôune mise √† jour ou d‚Äôun `Command`.

---

## **5. Streaming**

LangGraph permet le **streaming** :

1. **Streaming des √©v√©nements** : Les retours d‚Äôappels outils ou d‚Äôautres √©v√©nements peuvent √™tre stream√©s en direct.  
2. **Streaming token-par-token** (par exemple depuis un LLM) : Pour afficher une r√©ponse de chatbot au fur et √† mesure de sa g√©n√©ration.

Cela am√©liore la r√©activit√© per√ßue et permet de r√©aliser un suivi en temps r√©el de l‚Äôex√©cution.

---

## **6. Types de Graphes dans LangGraph**

- **StateGraph** : graphe standard, manipulant un √©tat d√©fini par l‚Äôutilisateur.  
- **MessageGraph** : graphe sp√©cialis√© pour des √©changes textuels ou des flux de messages (chatbots), int√©grant par d√©faut certains m√©canismes de gestion des messages.

Dans la pratique, la **distinction** est principalement un confort de mod√©lisation. Vous pouvez combiner librement les approches selon vos besoins.

---

## **7. Les R√©ducteurs (Reducers)**

Les r√©ducteurs d√©terminent **comment** sont appliqu√©es les mises √† jour sur l‚Äô√©tat global :

- **Par d√©faut** : la nouvelle valeur √©crase l‚Äôancienne.
- **R√©ducteur personnalis√©** : combiner ou fusionner les mises √† jour.  

> **Exemple de r√©ducteur add**  
> ```python
> from typing import Annotated
> from operator import add
> from typing_extensions import TypedDict
>
> class State(TypedDict):
>     foo: int
>     bar: Annotated[list[str], add]  # concat√®ne les listes
> ```

### 7.1. Gestion des messages

Pour les applications de type chatbot, on stocke souvent un **historique de messages** dans l‚Äô√©tat :

```python
from langchain_core.messages import AnyMessage
from langgraph.graph.message import add_messages
from typing import Annotated, List
from typing_extensions import TypedDict

class GraphState(TypedDict):
    messages: Annotated[List[AnyMessage], add_messages]
```

Le r√©ducteur `add_messages` g√®re la fusion et la d√©duplication (via IDs), et garantit que les messages sont correctement d√©s√©rialis√©s en objets `Message`.

---

## **8. Compilation et validation du graphe**

Avant utilisation, il faut toujours **compiler** le graphe :

```python
graph = builder.compile()
graph.invoke({"user_input": "Hello"})
```

La compilation :

- V√©rifie la **coh√©rence** du graphe (pas de n≈ìuds orphelins, etc.).
- Permet de sp√©cifier d‚Äô√©ventuels **checkpointers**, points d‚Äôarr√™t, etc.
- Pr√©pare le graphe pour l‚Äôex√©cution effective.

---

## **9. Configuration avanc√©e**

### 9.1. Config Schema

Vous pouvez d√©finir un sch√©ma de configuration pour injecter des **param√®tres dynamiques** (par exemple, type de LLM ou param√®tres d‚Äôhyperparam√®tres). Cette config est transmise aux n≈ìuds via le second argument :

```python
from typing_extensions import TypedDict

class ConfigSchema(TypedDict):
    llm: str

builder = StateGraph(dict, config_schema=ConfigSchema)

def node_llm(state: dict, config: dict):
    chosen_llm = config.get("configurable", {}).get("llm", "openai")
    ...
```

### 9.2. Limite de r√©cursion

LangGraph autorise par d√©faut **25 super-pas** maximum par ex√©cution. Vous pouvez ajuster via :

```python
graph.invoke(inputs, config={"recursion_limit": 5})
```

---

## **10. Subgraphs : modularit√© et r√©utilisation**

Les **sous-graphes (subgraphs)** sont des graphes autonomes que vous pouvez :

1. Compiler individuellement, puis ins√©rer comme n≈ìud dans un graphe parent.
2. Appeler explicitement via une fonction pour transformer l‚Äô√©tat avant/apr√®s.

**Cas 1 :** utilisation directe d‚Äôun subgraph compil√©  
```python
subgraph_builder = StateGraph(SubgraphState)
subgraph_builder.add_node(...)
subgraph = subgraph_builder.compile()

# Dans le graphe parent :
builder.add_node("subgraph", subgraph)
```

**Cas 2 :** invocation manuelle (lorsque les sch√©mas d‚Äô√©tat sont diff√©rents)  
```python
def call_subgraph(state: ParentState):
    subgraph_input = {"bar": state["foo"]}  # transformation
    result = subgraph.invoke(subgraph_input)
    return {"foo": result["bar"]}          # re-transformation
```

Cette approche facilite la **r√©utilisation** de blocs de logique (flux de travail, micro-services, gestion multi-agents, etc.).

---

## **11. Exemples concrets**

### 11.1. Exemple complet d‚Äôun Chatbot

Cet exemple minimal int√®gre un LLM, g√®re un historique de messages et ex√©cute un flux simple :

```python
# Importation du mod√®le ChatOllama (hypoth√©tique)
from langchain_ollama import ChatOllama
llm = ChatOllama(model="llama3.2", max_tokens=1024, temperature=0)

from langgraph.graph import StateGraph, START, END
from langchain_core.messages import AnyMessage
from typing_extensions import TypedDict
from typing import Annotated, List
from langgraph.graph.message import add_messages

# √âtat du chatbot (historique de messages)
class State(TypedDict):
    messages: Annotated[List[AnyMessage], add_messages]

graph_builder = StateGraph(State)

def chatbot(state: State):
    new_message = llm.invoke(state["messages"])
    return {"messages": [new_message]}

graph_builder.add_node("chatbot", chatbot)
graph_builder.add_edge(START, "chatbot")
graph_builder.add_edge("chatbot", END)

graph = graph_builder.compile()
```

Une fois compil√©, vous pouvez invoquer ce graphe avec un historique de messages initial, ou en conversation multiple (threads).

### 11.2. Visualisation graphique

LangGraph propose des fonctionnalit√©s pour g√©n√©rer une visualisation (Mermaid, etc.) :

```python
from IPython.display import Image, display

graph_image = graph.get_graph().draw_mermaid_png()
display(Image(graph_image))
```
*(Ou via LangGraph Studio.)*

![exemple_langraph.png](exemple_langraph.png)

---

## **12. Architectures d‚Äôagents avanc√©es**

### 12.1. Router (acheminement conditionnel)

Un ‚Äúrouter‚Äù est une forme d‚Äôagent qui d√©termine **un** chemin parmi plusieurs, souvent via un LLM qui renvoie un choix structur√© (JSON). Exemple :

1. Le LLM produit une sortie structur√©e ;
2. La sortie indique quel n≈ìud appeler ensuite ;
3. Le graphe ex√©cute le n≈ìud correspondant.

### 12.2. Tool-calling Agent (ex. ReAct)

Un agent ReAct (ou similaire) permet :

- Plusieurs √©tapes successives (‚Äúmulti-step‚Äù) ;
- Appel dynamique √† diff√©rents **outils** (tool-calling) ;
- Gestion d‚Äôune **m√©moire** de conversation/action ;
- Boucle de **planification** et de correction (auto-√©valuation).

### 12.3. Human-in-the-loop

Pour des t√¢ches critiques, vous pouvez ins√©rer des n≈ìuds n√©cessitant une intervention humaine :

- **Approbation** d‚Äôactions,
- **Correction** ou compl√©tion de r√©ponses,
- **Validation** avant de poursuivre.

### 12.4. Reflection et auto-r√©vision

Les agents peuvent s‚Äôauto-corriger :

- G√©n√©rer du code, d√©tecter des erreurs, it√©rer ;
- Analyser la pertinence de la r√©ponse (via LLM ou r√®gles m√©tier) et ajuster la requ√™te suivante.

LangGraph fournit la souplesse n√©cessaire pour impl√©menter ces boucles de feedback.

---

## **13. Command et contr√¥le de flux dynamique**

Le retour d‚Äôun n≈ìud peut √™tre un `Command`, combinant :

- `update` : mise √† jour de l‚Äô√©tat,
- `goto` ou `resume` : saut conditionnel vers d‚Äôautres n≈ìuds ou reprise apr√®s interruption.

**Exemple** :

```python
def my_node(state: dict) -> Command[Literal["my_other_node"]]:
    if state.get("need_tool"):
        return Command(update={"used_tool": True}, goto="my_other_node")
    else:
        return Command(update={"status": "done"}, goto="END")
```

---

## **14. Conclusion et perspectives**

LangGraph offre :

- Une **abstraction graphique** claire pour concevoir des workflows intelligents (chatbots, agents, syst√®mes multi-√©tapes).  
- Une **infrastructure de persistance** et d‚Äô**interruptions** pour int√©grer l‚Äôhumain dans la boucle et fiabiliser les ex√©cutions.  
- Des **fonctionnalit√©s de streaming**, de **visualisation**, de **d√©bogage** et de **d√©ploiement** avanc√©es.  
- Une **modularit√©** (subgraphs, config schemas) pour des architectures complexes ou multi-√©quipes.

Gr√¢ce √† ces concepts et exemples, vous disposez d‚Äôune **vision approfondie** de LangGraph. Vous pouvez d√©sormais :

1. Mettre en place des workflows simples ou complexes,  
2. G√©rer la m√©moire et la persistance pour cr√©er des chatbots ou des agents autonomes,  
3. Visualiser, d√©boguer et d√©ployer ais√©ment vos solutions.

LangGraph se veut un **framework ouvert**, fournissant des briques de bas niveau pour vous permettre de composer **votre propre architecture** (ou agent) et de l‚Äô**√©voluer** selon vos besoins. Bon d√©veloppement avec LangGraph !

## üìö Conclusion et perspectives

Gr√¢ce √† ce manuel d√©taill√© et exhaustif, vous disposez d√©sormais de toutes les connaissances n√©cessaires pour ma√Ætriser LangGraph, en structurant efficacement des workflows intelligents bas√©s sur des agents.

---