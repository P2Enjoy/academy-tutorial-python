{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ee070959-a6d9-4a66-9127-597bc9fd89b2",
   "metadata": {},
   "source": [
    "# Basic setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "428d5b96-9759-4ecb-82ec-110b4e479bae",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install --quiet -U --force transformers ipywidgets langchain langchain_community tiktoken langchain-nomic \"nomic[local]\" langchain-ollama scikit-learn langgraph "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "677d7dca-c960-491e-a741-76de07115b6d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Setup check-up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e12e7f82-d704-4cf4-aeb3-0d6e6e800421",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import langchain\n",
    "    print(\"Langchain est installé, version:\", langchain.__version__)\n",
    "except ImportError:\n",
    "    print(\"Langchain n'est pas installé.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f5f0ba2-ae71-4191-9795-55e4e87dbce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '1' \n",
    "\n",
    "try:\n",
    "    from transformers import pipeline\n",
    "    print(\"Hugging Face Transformers est installé.\")\n",
    "except ImportError:\n",
    "    print(\"Hugging Face Transformers n'est pas installé.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8815fd2-0ee6-4838-9711-3588e39b71f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import tensorflow as tf\n",
    "    print(\"TensorFlow est installé, version:\", tf.__version__)\n",
    "except ImportError:\n",
    "    print(\"TensorFlow n'est pas installé.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7367e30e-1a4d-464f-8b69-39d93193466d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8105b90a-afd7-42cf-9b78-a04222a58556",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Setup the LLM manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f931376-1d99-4809-9359-e6a6ec8feb1f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!docker create --gpus=all -v ollama:/root/.ollama -p 11434:11434 --name llm_server ollama/ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "718b2452-9096-492b-afce-07619b3b09c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "!docker ps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c937cd43-6595-4c26-9fd4-96fe9ecbebd9",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Run or stop the LLM server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5c070f4-7a52-4302-a6b1-cf2cd30862fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "!docker start llm_server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "376f21d8-7064-498d-b9e3-3840665b03ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "!docker stop llm_server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fee94ed2-1234-41e8-83e8-f3bb57985b55",
   "metadata": {},
   "outputs": [],
   "source": [
    "!yes | docker system prune -a"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d12f61f7-00a8-4cd8-a0f4-944fca6b3516",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Pull the desired modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51643d48-1398-4c38-9f99-f327d73c8655",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!docker exec -it llm_server ollama pull llama3.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94a70bae-d0c9-4fc4-8e2f-5eedce0baaad",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!docker exec -it llm_server ollama pull qwen2.5:32b-instruct-fp16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc53827d-e000-4b8b-afe4-579d3296fc11",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!docker exec -it llm_server ollama pull mistral-small"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8876c4c6-c8dd-493a-8c29-a8bf5600166d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!docker exec -it llm_server ollama pull nomic-embed-text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07f1a5ba-79fb-46f1-bb4b-ff459336f20f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Test the pulled model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "e26e527e-dbcd-4507-bd4c-b8b3525c216b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import OllamaLLM\n",
    "\n",
    "llm = OllamaLLM(model=\"llama3.2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "63d7d6fa-3d2b-40a6-9746-8301849a5826",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The first publicly large-scale available chat AI was ELIZA, developed in 1966 by Joseph Weizenbaum at the Massachusetts Institute of Technology (MIT).'"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.invoke(\"The first publicly large scale available chat AI was ...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbee3b67-60d1-4961-8a71-132448973cad",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Un simple chaîne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "dc47c172-452f-4b5f-9dfe-8533fdc28249",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import OllamaLLM\n",
    "\n",
    "sc_llm = OllamaLLM(model=\"llama3.2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "acf5bfcf-19ea-49b6-80d2-60069e86457c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing necessary modules from the LangChain core library\n",
    "from langchain_core.messages import HumanMessage, AIMessage  # To manage message types (human/system)\n",
    "from langchain_core.output_parsers import StrOutputParser  # To parse the output from the model\n",
    "from langchain_core.prompts import ChatPromptTemplate  # To create prompt templates for the LLM\n",
    "\n",
    "# Defining a system message template with a prompt that explains a specific topic\n",
    "system_template = \"Explain to the user the story of the {topic} he asked for.\"\n",
    "\n",
    "# Creating a ChatPromptTemplate object using system and user messages\n",
    "# The system message uses the 'system_template', while the user message contains the user's input as 'text'\n",
    "sc_prompt_template = ChatPromptTemplate.from_messages(\n",
    "    [system_template, \"{text}\"]\n",
    ")\n",
    "\n",
    "# Creating a string output parser to handle the output as plain text\n",
    "sc_parser = StrOutputParser()\n",
    "\n",
    "# Defining a chain that connects the prompt template, the LLM, and the output parser\n",
    "# This chain processes the prompt, generates the response, and parses it\n",
    "simplechain = sc_prompt_template | sc_llm | sc_parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "654029b1-b864-4903-bc26-4e3e7141d9aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'IBM Watson is a cloud-based artificial intelligence (AI) platform that uses natural language processing (NLP) and machine learning algorithms to analyze and understand human language. Developed by IBM in 2007, Watson was originally designed to compete on the game show \"Jeopardy!\" against two human champions.\\n\\nHere\\'s how it worked: Watson was trained on a massive database of text from various sources, including books, articles, and other information. The platform used NLP techniques to analyze and understand the language in the questions asked by the contestants. It could identify entities such as names, dates, and locations, extract key phrases, and even recognize nuances like idioms and metaphors.\\n\\nOn \"Jeopardy!\", Watson was presented with a series of questions in the form of clues, which it would then answer correctly in the format of \"What is [answer]?\" The human champions were surprised by Watson\\'s accuracy and speed, and it ultimately defeated them to win the show.\\n\\nAfter its success on \"Jeopardy!\", IBM expanded Watson\\'s capabilities beyond language processing to include areas like machine learning, data analytics, and natural language generation. Today, Watson is used in a wide range of applications, including healthcare, finance, customer service, and more.\\n\\nSome key features of IBM Watson include:\\n\\n1. Natural Language Understanding: Watson can understand the nuances of human language, including context, tone, and sentiment.\\n2. Entity Extraction: Watson can extract relevant information from text, such as names, locations, and dates.\\n3. Sentiment Analysis: Watson can analyze text to determine the sentiment or emotional tone behind it.\\n4. Question Answering: Watson can answer questions based on its training data.\\n\\nIBM Watson is available as a cloud-based service, which means it can be accessed and integrated into various applications and systems. Its use cases include:\\n\\n1. Customer Service: Watson-powered chatbots can provide 24/7 customer support and help with inquiries.\\n2. Healthcare: Watson can analyze medical records and diagnose diseases more accurately than human doctors.\\n3. Financial Services: Watson can analyze financial data to identify trends and predict market movements.\\n\\nOverall, IBM Watson is a powerful platform that uses NLP and machine learning to analyze and understand human language, making it an invaluable tool for businesses and organizations looking to leverage AI capabilities.'"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simplechain.invoke({\"topic\": \"Natural Language Processing\", \"text\": \"Tell me more about IBM Watson\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7affd291-6081-49be-a922-5ec72704f50f",
   "metadata": {},
   "source": [
    "# Exemples Langchain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5550640-e921-449a-9276-fcf3d01bb476",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Structured Output Parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d51e83f5-72e7-436e-8bb7-da09920bf5d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'raw': AIMessage(content='', additional_kwargs={}, response_metadata={'model': 'llama3.2', 'created_at': '2024-10-06T18:31:40.443422938Z', 'message': {'role': 'assistant', 'content': '', 'tool_calls': [{'function': {'name': 'ResponseFormatter', 'arguments': {'answer': 'Paris', 'followup_question': ''}}}]}, 'done_reason': 'stop', 'done': True, 'total_duration': 172617532, 'load_duration': 15431599, 'prompt_eval_count': 190, 'prompt_eval_duration': 7285000, 'eval_count': 24, 'eval_duration': 106020000}, id='run-b183d3ba-b3df-42f1-961f-2bd67ecb89cf-0', tool_calls=[{'name': 'ResponseFormatter', 'args': {'answer': 'Paris', 'followup_question': ''}, 'id': 'c406a4cc-dbc9-4262-bcf7-fdf51281cbd5', 'type': 'tool_call'}], usage_metadata={'input_tokens': 190, 'output_tokens': 24, 'total_tokens': 214}), 'parsed': ResponseFormatter(answer='Paris', followup_question=''), 'parsing_error': None}\n"
     ]
    }
   ],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "from langchain_ollama import ChatOllama\n",
    "\n",
    "# Définition d'un modèle Pydantic pour la sortie\n",
    "class ResponseFormatter(BaseModel):\n",
    "    answer: str = Field(description=\"La réponse à la question de l'utilisateur.\")\n",
    "    followup_question: str = Field(description=\"Une question de suivi que l'utilisateur pourrait poser.\")\n",
    "\n",
    "# Initialiser le modèle de chat\n",
    "# llm = ChatOllama(model=\"mistral-small\", format=\"json\")\n",
    "so_llm = ChatOllama(model=\"llama3.2\")\n",
    "\n",
    "# Lier le modèle à l'output structuré\n",
    "structured_model = so_llm.with_structured_output(ResponseFormatter,include_raw=True)\n",
    "\n",
    "# Exemple d'invocation\n",
    "response = structured_model.invoke(\"Quel est le capital de la France ?\")\n",
    "\n",
    "# Afficher la sortie structurée\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5c294eb1-21fd-4803-899f-60a83fafcdd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quelle est la préfecture administrative de la région Île-de-France ?\n"
     ]
    }
   ],
   "source": [
    "print(response.followup_question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "65fde763-2347-4ee9-a243-33ce31d58459",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The output should be formatted as a JSON instance that conforms to the JSON schema below.\\n\\nAs an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\\nthe object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\\n\\nHere is the output schema:\\n```\\n{\"properties\": {\"answer\": {\"description\": \"La réponse à la question de l\\'utilisateur.\", \"title\": \"Answer\", \"type\": \"string\"}, \"followup_question\": {\"description\": \"Une question de suivi que l\\'utilisateur pourrait poser.\", \"title\": \"Followup Question\", \"type\": \"string\"}}, \"required\": [\"answer\", \"followup_question\"]}\\n```'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parser = PydanticOutputParser(pydantic_object=ResponseFormatter)\n",
    "parser.get_format_instructions()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0504637-92d7-486c-afa8-6349b5cca0ea",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Le Templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7d0759be-5bfa-49f0-8ab6-ba5bd8de66da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StringPromptValue(text='Donne-moi une blague sur les chats.')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "prompt_template = PromptTemplate.from_template(\"Donne-moi une blague sur {sujet}.\")\n",
    "response = prompt_template.invoke({\"sujet\": \"les chats\"})\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "95ea1c6e-1ccb-41fc-9d5f-7ce4b681316c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptValue(messages=[SystemMessage(content='Tu es un assistant utile.', additional_kwargs={}, response_metadata={}), HumanMessage(content='Raconte-moi une blague sur les chats.', additional_kwargs={}, response_metadata={})])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt_template = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"Tu es un assistant utile.\"),\n",
    "    (\"user\", \"Raconte-moi une blague sur les chats.\")\n",
    "])\n",
    "response = prompt_template.invoke({})\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3eff35d-c1d2-4ff3-a837-8f0b75c09c28",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Les embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a0d1a69c-dfa5-4a8e-807b-42bc51f219f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "768\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[-0.33447709679603577,\n",
       " 0.6420562267303467,\n",
       " 1.4902821779251099,\n",
       " 0.5697729587554932,\n",
       " 0.009297564625740051,\n",
       " 0.430616557598114,\n",
       " -0.6175608038902283,\n",
       " -0.03231702744960785,\n",
       " -0.4382496178150177,\n",
       " 0.08225058764219284]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.embeddings import OllamaEmbeddings\n",
    "from langchain_core.vectorstores import InMemoryVectorStore\n",
    "\n",
    "# Initialize Ollama embeddings model\n",
    "embeddings = OllamaEmbeddings(model=\"nomic-embed-text\")\n",
    "\n",
    "# Sample text for vector store\n",
    "text = \"LangChain is the framework for building context-aware reasoning applications\"\n",
    "vector = embeddings.embed_query(text)\n",
    "\n",
    "print(len(vector))\n",
    "vector[10:20] # j'affiche que 10 dimensions sur 768, pour la démonstration.."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a853f2b0-7315-46ea-a568-c25b1b347319",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Les Vector Stores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "56ec1b1a-32b9-4660-b19e-39672180fed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an in-memory vector store and populate it with embeddings of the sample text\n",
    "vectorstore = InMemoryVectorStore.from_texts(\n",
    "    [\n",
    "        \"It's cool to be a BBS student\",\n",
    "        \"I wish I could have chicken wings right now\",\n",
    "        \"Sorry, wasn't listening\"\n",
    "    ],\n",
    "    embedding=embeddings\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "03bf9636-d7f6-4150-bd8b-54184e4ce31d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* I wish I could have chicken wings right now [{}]\n"
     ]
    }
   ],
   "source": [
    "for doc in vectorstore.similarity_search(query=\"fried chicken\",k=1):\n",
    "    print(f\"* {doc.page_content} [{doc.metadata}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "69234fd8-80ef-463f-a761-ff0f3be919fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* [SIM=54.748526%] I wish I could have chicken wings right now [{}]\n",
      "* [SIM=38.325593%] It's cool to be a BBS student [{}]\n"
     ]
    }
   ],
   "source": [
    "for doc, score in vectorstore.similarity_search_with_score(query=\"fried chicken\",k=2):\n",
    "    print(f\"* [SIM={(score*100):3f}%] {doc.page_content} [{doc.metadata}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "333fb002-67a8-48b5-aee6-a321812ed711",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Les retrievers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b5b2110-78d0-44c7-9da6-50a3eae65cb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install wikipedia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65f26c4e-a88c-4d6f-aa2a-e81ecf026cbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.retrievers import WikipediaRetriever\n",
    "\n",
    "wikiretriever = WikipediaRetriever()\n",
    "documents = wikiretriever.invoke(\"intelligence artificielle\")\n",
    "documents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ffcbb51-27e8-4a19-b8b5-10977e9a716f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Vector Store Retrievers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "ca06421d-771a-4fc1-bfec-1ae0aea3fc81",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id='d289ad5e-017b-44d7-af4b-87208afd7083', metadata={}, page_content='I wish I could have chicken wings right now')]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use the vector store as a retriever (Can be “similarity” (default), “mmr”, or “similarity_score_threshold”)\n",
    "mmrretriever = vectorstore.as_retriever(\n",
    "    search_type=\"mmr\",\n",
    "    search_kwargs={\"k\": 1, \"fetch_k\": 2, \"lambda_mult\": 0.5},\n",
    ")\n",
    "\n",
    "# Query the retriever with a relevant question\n",
    "retrieved_documents = mmrretriever.invoke(\"Fried chicken?\")\n",
    "\n",
    "# Show the retrieved document's content\n",
    "retrieved_documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "16b9a381-4e06-471d-8608-7c094dd6a39a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id='b1454c20-99dd-4191-b98b-80cd3296e0d4', metadata={'title': 'Yann LeCun', 'summary': 'Yann André LeCun ( lə-KUN, French: [ləkœ̃]; originally spelled Le Cun; born 8 July 1960) is a French-American computer scientist working primarily in the fields of machine learning, computer vision, mobile robotics and computational neuroscience. He is the Silver Professor of the Courant Institute of Mathematical Sciences at New York University and Vice-President, Chief AI Scientist at Meta.\\nHe is well known for his work on optical character recognition and computer vision using convolutional neural networks (CNNs). He is also one of the main creators of the DjVu image compression technology (together with Léon Bottou and Patrick Haffner). He co-developed the Lush programming language with Léon Bottou.\\nIn 2018, LeCun, Yoshua Bengio, and Geoffrey Hinton, received the Turing Award for their work on deep learning. The three are sometimes referred to as the \"Godfathers of AI\" and \"Godfathers of Deep Learning\".', 'source': 'https://en.wikipedia.org/wiki/Yann_LeCun'}, page_content='Yann André LeCun ( lə-KUN, French: [ləkœ̃]; originally spelled Le Cun; born 8 July 1960) is a French-American computer scientist working primarily in the fields of machine learning, computer vision, mobile robotics and computational neuroscience. He is the Silver Professor of the Courant Institute of Mathematical Sciences at New York University and Vice-President, Chief AI Scientist at Meta.\\nHe is well known for his work on optical character recognition and computer vision using convolutional neural networks (CNNs). He is also one of the main creators of the DjVu image compression technology (together with Léon Bottou and Patrick Haffner). He co-developed the Lush programming language with Léon Bottou.\\nIn 2018, LeCun, Yoshua Bengio, and Geoffrey Hinton, received the Turing Award for their work on deep learning. The three are sometimes referred to as the \"Godfathers of AI\" and \"Godfathers of Deep Learning\".\\n\\n\\n== Early life and education ==\\n\\nLeCun was born on 8 July 1960, at Soisy-sous-Montmorency in the suburbs of Paris. His name was originally spelled Le Cun from the old Breton form Le Cunff and was from the region of Guingamp in northern Brittany. \"Yann\" is the Breton form for \"John\".\\nHe received a Diplôme d\\'Ingénieur from the ESIEE Paris in 1983 and a PhD in Computer Science from Université Pierre et Marie Curie (today Sorbonne University) in 1987 during which he proposed an early form of the back-propagation learning algorithm for neural networks.\\n\\n\\n== Career ==\\n\\n\\n=== Bell Labs ===\\nIn 1988, LeCun joined the Adaptive Systems Research Department at AT&T Bell Laboratories in Holmdel, New Jersey, United States, headed by Lawrence D. Jackel, where he developed a number of new machine learning methods, such as a biologically inspired model of image recognition called convolutional neural networks, the \"Optimal Brain Damage\" regularisation methods, and the Graph Transformer Networks method (similar to conditional random field), which he applied to handwriting recognition and OCR. The bank check recognition system that he helped develop was widely deployed by NCR and other companies, reading over 10% of all the checks in the US in the late 1990s and early 2000s.\\nIn 1996, he joined AT&T Labs-Research as head of the Image Processing Research Department, which was part of Lawrence Rabiner\\'s Speech and Image Processing Research Lab, and worked primarily on the DjVu image compression technology, used by many websites, notably the Internet Archive, to distribute scanned documents. His collaborators at AT&T include Léon Bottou and Vladimir Vapnik.\\n\\n\\n=== New York University ===\\nAfter a brief tenure as a Fellow of the NEC Research Institute (now NEC-Labs America) in Princeton, NJ, LeCun joined New York University (NYU) in 2003, where he is Jacob T. Schwartz Chaired Professor of Computer Science and Neural Science at the Courant Institute of Mathematical Sciences and the Center for Neural Science. He is also a professor at the Tandon School of Engineering. At NYU, he has worked primarily on Energy-Based Models for supervised and unsupervised learning, feature learning for object recognition in Computer Vision, and mobile robotics.\\nIn 2012, he became the founding director of the NYU Center for Data Science. On 9 December 2013, LeCun became the first director of Meta AI Research in New York City, and stepped down from the NYU-CDS directorship in early 2014.\\nIn 2013, he and Yoshua Bengio co-founded the International Conference on Learning Representations, which adopted a post-publication open review process he previously advocated on his website. He was the chair and organiser of the \"Learning Workshop\" held every year between 1986 and 2012 in Snowbird, Utah. He is a member of the Science Advisory Board of the Institute for Pure and Applied Mathematics at UCLA. He is the Co-Director of the Learning in Machines and Brain research program (formerly Neural Computation & Adaptive Perception) of CIFAR.\\nIn 2016, he was the visiting professor of compu'),\n",
       " Document(id='bee63c71-adcd-46e8-8531-0b813ba1eca9', metadata={'title': 'Watershed (image processing)', 'summary': 'In the study of image processing, a watershed is a transformation defined on a grayscale image. The name refers metaphorically to a geological watershed, or drainage divide, which separates adjacent drainage basins. The watershed transformation treats the image it operates upon like a topographic map, with the brightness of each point representing its height, and finds the lines that run along the tops of ridges.\\nThere are different technical definitions of a watershed. In graphs, watershed lines may be defined on the nodes, on the edges, or hybrid lines on both nodes and edges. Watersheds may also be defined in the continuous domain. There are also many different algorithms to compute watersheds. Watershed algorithms are used in image processing primarily for object segmentation purposes, that is, for separating different objects in an image. This allows for counting the objects or for further analysis of the separated objects.\\n\\n\\t\\t\\n\\t\\t\\t\\n\\t\\t\\t\\n\\t\\t\\n\\t\\t\\n\\t\\t\\t\\n\\t\\t\\t\\n\\t\\t\\n\\t\\t\\n\\t\\t\\t\\n\\t\\t\\t\\n\\t\\t\\n\\t\\t\\n\\t\\t\\t\\n\\t\\t\\t\\n\\t\\t\\n\\n', 'source': 'https://en.wikipedia.org/wiki/Watershed_(image_processing)'}, page_content='In the study of image processing, a watershed is a transformation defined on a grayscale image. The name refers metaphorically to a geological watershed, or drainage divide, which separates adjacent drainage basins. The watershed transformation treats the image it operates upon like a topographic map, with the brightness of each point representing its height, and finds the lines that run along the tops of ridges.\\nThere are different technical definitions of a watershed. In graphs, watershed lines may be defined on the nodes, on the edges, or hybrid lines on both nodes and edges. Watersheds may also be defined in the continuous domain. There are also many different algorithms to compute watersheds. Watershed algorithms are used in image processing primarily for object segmentation purposes, that is, for separating different objects in an image. This allows for counting the objects or for further analysis of the separated objects.\\n\\n\\t\\t\\n\\t\\t\\t\\n\\t\\t\\t\\n\\t\\t\\n\\t\\t\\n\\t\\t\\t\\n\\t\\t\\t\\n\\t\\t\\n\\t\\t\\n\\t\\t\\t\\n\\t\\t\\t\\n\\t\\t\\n\\t\\t\\n\\t\\t\\t\\n\\t\\t\\t\\n\\t\\t\\n\\n\\n== Definitions ==\\nIn geology, a watershed is a divide that separates adjacent catchment basins.\\n\\n\\n=== Watershed by flooding ===\\nThe idea was introduced in 1979 by S. Beucher and C. Lantuéjoul. The basic idea consisted of placing a water source in each regional minimum in the relief, to flood the entire relief from sources, and build barriers when different water sources meet. The resulting set of barriers constitutes                                                                      a watershed by flooding. A number of improvements, collectively called Priority-Flood, have since been made to this algorithm.\\n\\n\\n=== Watershed by topographic distance ===\\nIntuitively, a drop of water falling on a topographic relief flows towards the \"nearest\" minimum.  The \"nearest\" minimum is that minimum which lies at the end of the path of steepest descent.  In terms of topography, this occurs if the point lies in the catchment basin of that minimum. The previous definition does not verify this condition.\\n\\n\\n=== Watershed by the drop of water principle ===\\nIntuitively, the watershed is a separation of the regional minima from which a drop of water can flow down towards distinct minima. A formalization of this intuitive idea was provided in  for defining a watershed of an edge-weighted graph.\\n\\n\\n=== Inter-pixel watershed ===\\nS. Beucher and F. Meyer introduced an algorithmic inter-pixel implementation of the watershed method, given the following procedure:\\n\\nLabel each minimum with a distinct label. Initialize a set S with the labeled nodes.\\nExtract from S a node x of minimal altitude F, that is to say F(x) = min{F(y)|y ∈ S}. Attribute the label of x to each non-labeled node y adjacent to x, and insert y in S.\\nRepeat Step 2 until S is empty.\\n\\n\\n=== Topological watershed ===\\nPrevious notions focus on catchment basins, but not to the produced separating line. The topological watershed was introduced by M. Couprie and G. Bertrand in 1997, and beneficiate of the following fundamental property.\\nA function W is a watershed of a function F if and only if W ≤ F and W preserves the contrast between the regional minima of F; where the contrast between two regional minima M1 and M2 is defined as the minimal altitude to which one must climb in order to go from M1 to M2. An efficient algorithm is detailed in the paper.\\nWatershed algorithm\\nDifferent approaches may be employed to use the watershed principle for image segmentation.\\n\\nLocal minima of the gradient of the image may be chosen as markers, in this case an over-segmentation is produced and a second step involves region merging.\\nMarker based watershed transformation make use of specific marker positions which have been either explicitly defined by the user or determined automatically with morphological operators or other ways.\\n\\n\\n=== Meyer\\'s flooding algorithm ===\\nOne of the most common watershed algorithms was introduced by F. Meyer in the early 1990s, though a number of improvements, collectively called Priority-Flood, have'),\n",
       " Document(id='dfd92cd5-6d9e-40c8-b077-5300525541e4', metadata={'title': 'Les Prophéties', 'summary': 'Les Prophéties (The Prophecies) is a collection of prophecies by French physician Nostradamus, the first edition of which appeared in 1555 by the publishing house Macé Bonhomme. His most famous work is a collection of poems, quatrains, united in ten sets of verses (\"Centuries\") of 100 quatrains each.\\nThe first edition included three whole Centuries and 53 quatrains. The book begins with a preface, in the form of a message to his son César, followed by the Centuries themselves. The second edition was published in the same year and has minor differences from the first.\\nThe third edition was published in 1557, and included the full text of the previous edition, supplemented by three more Centuries. The fourth edition was published two years after the death of the author, in 1568. It is the first edition to include all ten Centuries, as well as a second preface, the Letter to King Henry II. However, quatrains 55 to 100 of the seventh Century were never completed.\\nThe first English edition titled The True Prophecies or Prognostications of Michael Nostradamus, Physician to Henry II. Francis II. and Charles IX. Kings of France, was published in London by Thomas Ratcliffe and Nathaniel, in the year 1672.\\nThe predictions do not follow chronological coherence and were written combining French, Greek, Latin and Occitan. It is believed that it contains anagrams, mythological and astrological references, in a subjective language that makes comprehension difficult. Some scholars claim that this was a resource used by Nostradamus to evade the Holy Inquisition, for fear of being persecuted for heresy.\\nMost of the quatrains deal with disasters, and Nostradamus gained notoriety for the belief in his ability to predict the future.\\n\\n', 'source': 'https://en.wikipedia.org/wiki/Les_Proph%C3%A9ties'}, page_content='Les Prophéties (The Prophecies) is a collection of prophecies by French physician Nostradamus, the first edition of which appeared in 1555 by the publishing house Macé Bonhomme. His most famous work is a collection of poems, quatrains, united in ten sets of verses (\"Centuries\") of 100 quatrains each.\\nThe first edition included three whole Centuries and 53 quatrains. The book begins with a preface, in the form of a message to his son César, followed by the Centuries themselves. The second edition was published in the same year and has minor differences from the first.\\nThe third edition was published in 1557, and included the full text of the previous edition, supplemented by three more Centuries. The fourth edition was published two years after the death of the author, in 1568. It is the first edition to include all ten Centuries, as well as a second preface, the Letter to King Henry II. However, quatrains 55 to 100 of the seventh Century were never completed.\\nThe first English edition titled The True Prophecies or Prognostications of Michael Nostradamus, Physician to Henry II. Francis II. and Charles IX. Kings of France, was published in London by Thomas Ratcliffe and Nathaniel, in the year 1672.\\nThe predictions do not follow chronological coherence and were written combining French, Greek, Latin and Occitan. It is believed that it contains anagrams, mythological and astrological references, in a subjective language that makes comprehension difficult. Some scholars claim that this was a resource used by Nostradamus to evade the Holy Inquisition, for fear of being persecuted for heresy.\\nMost of the quatrains deal with disasters, and Nostradamus gained notoriety for the belief in his ability to predict the future.\\n\\n\\n== References ==\\n\\n\\n== Sources ==\\nLeoni, E., Nostradamus and His Prophecies (Wings, 1961–82)\\nLemesurier, P., The Nostradamus Encyclopedia (Godsfield/St Martin’s, 1997)\\nLemesurier, P., Nostradamus – The Illustrated Prophecies (O Books, 2003)\\nWilson, I., Nostradamus: The Evidence (Orion, 2002)/ Nostradamus: The Man Behind the Prophecies (St Martin\\'s 2007)\\n\\n\\n== External links ==\\n\\n Les Prophéties at Project Gutenberg\\nFull text of the Letter to King Henry II in English\\nFacsimiles of original editions from 1568 onwards Archived 2008-12-31 at the Wayback Machine')]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create an in-memory vector store and populate it with embeddings of the sample text\n",
    "wikivectorstore = InMemoryVectorStore.from_documents(\n",
    "    documents,\n",
    "    embedding=embeddings\n",
    ")\n",
    "\n",
    "# Use the vector store as a retriever (all defaults to cosine similarity)\n",
    "wikiretriever = wikivectorstore.as_retriever()\n",
    "\n",
    "# Query the retriever with a relevant question\n",
    "retrieved_documents = wikiretriever.invoke(\"Any knowledge about teh Dartmouth conference?\")\n",
    "\n",
    "# Show the retrieved document's content\n",
    "retrieved_documents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a47b71cb-d081-42d3-9b54-2c25132a6eab",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "13d6bff3-eb9c-4e8b-81bd-3daa8b155647",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "\n",
    "llm = ChatOllama(model=\"llama3.2\", temperature=0)\n",
    "query = \"What is 3 * 12? Also, what is 11 + 49?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "606b4c83-875f-4964-a3d4-64c53ce57ad7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='', additional_kwargs={}, response_metadata={'model': 'llama3.2', 'created_at': '2024-10-06T21:22:53.229805053Z', 'message': {'role': 'assistant', 'content': '', 'tool_calls': [{'function': {'name': 'multiply', 'arguments': {'a': '3', 'b': '12'}}}, {'function': {'name': 'add', 'arguments': {'a': '11', 'b': '49'}}}]}, 'done_reason': 'stop', 'done': True, 'total_duration': 262830504, 'load_duration': 15371968, 'prompt_eval_count': 236, 'prompt_eval_duration': 7194000, 'eval_count': 44, 'eval_duration': 196538000}, id='run-35eb4f94-a887-41c5-89a4-d09530cbb44a-0', tool_calls=[{'name': 'multiply', 'args': {'a': '3', 'b': '12'}, 'id': 'bf260269-63e3-4927-ba90-5c426a508a34', 'type': 'tool_call'}, {'name': 'add', 'args': {'a': '11', 'b': '49'}, 'id': 'a4c53aed-bd86-4f26-8c50-aae502a2d5db', 'type': 'tool_call'}], usage_metadata={'input_tokens': 236, 'output_tokens': 44, 'total_tokens': 280})"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tools déclarés \n",
    "from langchain_core.output_parsers import PydanticToolsParser\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "class add(BaseModel):\n",
    "    \"\"\"Add two integers.\"\"\"\n",
    "\n",
    "    a: int = Field(..., description=\"First integer\")\n",
    "    b: int = Field(..., description=\"Second integer\")\n",
    "\n",
    "class multiply(BaseModel):\n",
    "    \"\"\"Multiply two integers.\"\"\"\n",
    "\n",
    "    a: int = Field(..., description=\"First integer\")\n",
    "    b: int = Field(..., description=\"Second integer\")\n",
    "\n",
    "available_tools = [add, multiply]\n",
    "llm_with_tools = llm.bind_tools(available_tools)\n",
    "llm_with_tools.invoke(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aea0f975-e1e2-4218-a367-3b2c100d6848",
   "metadata": {},
   "source": [
    "### Tool output parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "aeadd9a0-da88-4fe2-9f43-f6be9438d21a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[multiply(a=3, b=12), add(a=11, b=49)]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain = llm_with_tools | PydanticToolsParser(tools=available_tools)\n",
    "\n",
    "response = chain.invoke(query)\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6846c5e-f7b1-43a6-adb1-ae1dce940cdb",
   "metadata": {},
   "source": [
    "## Tracing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "113a28cd-1d8d-4239-b5f7-44a9771172ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any, Dict, List, Optional, Sequence\n",
    "from uuid import UUID\n",
    "\n",
    "# from langchain_ollama import OllamaLLM\n",
    "# from langchain_core.callbacks.base import BaseCallbackHandler\n",
    "# from langchain_core.agents import AgentAction, AgentFinish\n",
    "# from langchain_core.messages import BaseMessage, HumanMessage, AIMessage\n",
    "# from langchain_core.output_parsers import StrOutputParser\n",
    "# from langchain_core.prompts import ChatPromptTemplate\n",
    "# from langchain_core.schema import GenerationChunk, ChatGenerationChunk, RetryCallState\n",
    "# from langchain_core.retrievers import Document\n",
    "\n",
    "from langchain_ollama import OllamaLLM\n",
    "from langchain_core.callbacks.base import BaseCallbackHandler\n",
    "from langchain_core.agents import AgentAction, AgentFinish\n",
    "from langchain_core.messages.base import BaseMessage\n",
    "from langchain_core.outputs.llm_result import LLMResult\n",
    "from langchain_core.outputs.chat_generation import ChatGenerationChunk\n",
    "from langchain_core.outputs.generation import GenerationChunk\n",
    "from langchain_core.documents.base import Document\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "from langchain_ollama import OllamaLLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "734b0536-802a-412f-8e8d-ee9a61bf9bbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LoggingHandler(BaseCallbackHandler):\n",
    "    ##### GENERAL CASE INSPECTIONS\n",
    "    # def on_retry(\n",
    "    #     self,\n",
    "    #     retry_state: RetryCallState,\n",
    "    #     *,\n",
    "    #     run_id: UUID,\n",
    "    #     parent_run_id: Optional[UUID] = None,\n",
    "    #     **kwargs: Any\n",
    "    # ) -> Any:\n",
    "    #     print(f\"[Run ID: {run_id}] Retry occurred. Retry state: {retry_state}\")\n",
    "\n",
    "    def on_text(\n",
    "        self,\n",
    "        text: str,\n",
    "        *,\n",
    "        run_id: UUID,\n",
    "        parent_run_id: Optional[UUID] = None,\n",
    "        **kwargs: Any\n",
    "    ) -> Any:\n",
    "        print(f\"[Run ID: {run_id}] Text event: {text}\")\n",
    "\n",
    "    ##### AGENTS INSPECTIONS \n",
    "    def on_agent_action(\n",
    "        self,\n",
    "        action: AgentAction,\n",
    "        *,\n",
    "        run_id: UUID,\n",
    "        parent_run_id: Optional[UUID] = None,\n",
    "        **kwargs: Any\n",
    "    ) -> Any:\n",
    "        print(f\"[Run ID: {run_id}] Agent Action: {action}\")\n",
    "\n",
    "    def on_agent_finish(\n",
    "        self,\n",
    "        finish: AgentFinish,\n",
    "        *,\n",
    "        run_id: UUID,\n",
    "        parent_run_id: Optional[UUID] = None,\n",
    "        **kwargs: Any\n",
    "    ) -> Any:\n",
    "        print(f\"[Run ID: {run_id}] Agent Finished: {finish}\")\n",
    "\n",
    "    ##### CHAINS INSPECTIONS\n",
    "    def on_chain_end(\n",
    "        self,\n",
    "        outputs: Dict[str, Any],\n",
    "        *,\n",
    "        run_id: UUID,\n",
    "        parent_run_id: Optional[UUID] = None,\n",
    "        **kwargs: Any\n",
    "    ) -> Any:\n",
    "        print(f\"[Run ID: {run_id}] Chain Ended with outputs: {outputs}\")\n",
    "\n",
    "    def on_chain_error(\n",
    "        self,\n",
    "        error: BaseException,\n",
    "        *,\n",
    "        run_id: UUID,\n",
    "        parent_run_id: Optional[UUID] = None,\n",
    "        **kwargs: Any\n",
    "    ) -> Any:\n",
    "        print(f\"[Run ID: {run_id}] Chain Error: {error}\")\n",
    "\n",
    "    def on_chain_start(\n",
    "        self,\n",
    "        serialized: Optional[Dict[str, Any]],  # Allow serialized to be Optional\n",
    "        inputs: Dict[str, Any],\n",
    "        *,\n",
    "        run_id: UUID,\n",
    "        parent_run_id: Optional[UUID] = None,\n",
    "        tags: Optional[List[str]] = None,\n",
    "        metadata: Optional[Dict[str, Any]] = None,\n",
    "        **kwargs: Any\n",
    "    ) -> Any:\n",
    "        if serialized is None:\n",
    "            chain_name = \"Unnamed Chain\"\n",
    "            print(f\"[Run ID: {run_id}] WARNING: Received None for 'serialized' in on_chain_start.\")\n",
    "        else:\n",
    "            chain_name = serialized.get(\"name\", \"Unnamed Chain\")\n",
    "\n",
    "        print(f\"[Run ID: {run_id}] INFO: Chain '{chain_name}' started with inputs: {inputs}\")\n",
    "\n",
    "\n",
    "    ##### CHAT MODEL INSPECTIONS\n",
    "    def on_chat_model_start(\n",
    "        self,\n",
    "        serialized: Dict[str, Any],\n",
    "        messages: List[List[BaseMessage]],\n",
    "        *,\n",
    "        run_id: UUID,\n",
    "        parent_run_id: Optional[UUID] = None,\n",
    "        tags: Optional[List[str]] = None,\n",
    "        metadata: Optional[Dict[str, Any]] = None,\n",
    "        **kwargs: Any\n",
    "    ) -> Any:\n",
    "        model_name = serialized.get(\"model\", \"Unnamed Model\")\n",
    "        print(f\"[Run ID: {run_id}] Chat Model '{model_name}' started with messages: {messages}\")\n",
    "\n",
    "    ##### CUSTOM EVENTS INSPECTIONS\n",
    "    def on_custom_event(\n",
    "        self,\n",
    "        name: str,\n",
    "        data: Any,\n",
    "        *,\n",
    "        run_id: UUID,\n",
    "        tags: Optional[List[str]] = None,\n",
    "        metadata: Optional[Dict[str, Any]] = None,\n",
    "        **kwargs: Any\n",
    "    ) -> Any:\n",
    "        print(f\"[Run ID: {run_id}] Custom Event '{name}' triggered with data: {data}\")\n",
    "\n",
    "    ##### LLM INSPECTIONS\n",
    "    def on_llm_end(\n",
    "        self,\n",
    "        response: Any,  # Adjusted to Any since OllamaLLM might return different types\n",
    "        *,\n",
    "        run_id: UUID,\n",
    "        parent_run_id: Optional[UUID] = None,\n",
    "        **kwargs: Any\n",
    "    ) -> Any:\n",
    "        print(f\"[Run ID: {run_id}] LLM Ended with response: {response}\")\n",
    "\n",
    "    def on_llm_error(\n",
    "        self,\n",
    "        error: BaseException,\n",
    "        *,\n",
    "        run_id: UUID,\n",
    "        parent_run_id: Optional[UUID] = None,\n",
    "        **kwargs: Any\n",
    "    ) -> Any:\n",
    "        print(f\"[Run ID: {run_id}] LLM Error: {error}\")\n",
    "\n",
    "    def on_llm_new_token(\n",
    "        self,\n",
    "        token: str,\n",
    "        *,\n",
    "        chunk: Optional[GenerationChunk] = None,\n",
    "        run_id: UUID,\n",
    "        parent_run_id: Optional[UUID] = None,\n",
    "        **kwargs: Any\n",
    "    ) -> Any:\n",
    "        print(f\"[Run ID: {run_id}] New LLM Token: {token}\")\n",
    "\n",
    "    def on_llm_start(\n",
    "        self,\n",
    "        serialized: Dict[str, Any],\n",
    "        prompts: List[str],\n",
    "        *,\n",
    "        run_id: UUID,\n",
    "        parent_run_id: Optional[UUID] = None,\n",
    "        tags: Optional[List[str]] = None,\n",
    "        metadata: Optional[Dict[str, Any]] = None,\n",
    "        **kwargs: Any\n",
    "    ) -> Any:\n",
    "        llm_name = serialized.get(\"model\", \"Unnamed LLM\")\n",
    "        print(f\"[Run ID: {run_id}] LLM '{llm_name}' started with prompts: {prompts}\")\n",
    "\n",
    "    ##### RETRIEVERS INSPECTIONS\n",
    "    def on_retriever_end(\n",
    "        self,\n",
    "        documents: Sequence[Document],\n",
    "        *,\n",
    "        run_id: UUID,\n",
    "        parent_run_id: Optional[UUID] = None,\n",
    "        **kwargs: Any\n",
    "    ) -> Any:\n",
    "        print(f\"[Run ID: {run_id}] Retriever Ended with documents: {documents}\")\n",
    "\n",
    "    def on_retriever_error(\n",
    "        self,\n",
    "        error: BaseException,\n",
    "        *,\n",
    "        run_id: UUID,\n",
    "        parent_run_id: Optional[UUID] = None,\n",
    "        **kwargs: Any\n",
    "    ) -> Any:\n",
    "        print(f\"[Run ID: {run_id}] Retriever Error: {error}\")\n",
    "\n",
    "    def on_retriever_start(\n",
    "        self,\n",
    "        serialized: Dict[str, Any],\n",
    "        query: str,\n",
    "        *,\n",
    "        run_id: UUID,\n",
    "        parent_run_id: Optional[UUID] = None,\n",
    "        tags: Optional[List[str]] = None,\n",
    "        metadata: Optional[Dict[str, Any]] = None,\n",
    "        **kwargs: Any\n",
    "    ) -> Any:\n",
    "        retriever_name = serialized.get(\"name\", \"Unnamed Retriever\")\n",
    "        print(f\"[Run ID: {run_id}] Retriever '{retriever_name}' started with query: '{query}'\")\n",
    "\n",
    "    ##### TOOLS INSPECTIONS\n",
    "    def on_tool_end(\n",
    "        self,\n",
    "        output: Any,\n",
    "        *,\n",
    "        run_id: UUID,\n",
    "        parent_run_id: Optional[UUID] = None,\n",
    "        **kwargs: Any\n",
    "    ) -> Any:\n",
    "        print(f\"[Run ID: {run_id}] Tool Ended with output: {output}\")\n",
    "\n",
    "    def on_tool_error(\n",
    "        self,\n",
    "        error: BaseException,\n",
    "        *,\n",
    "        run_id: UUID,\n",
    "        parent_run_id: Optional[UUID] = None,\n",
    "        **kwargs: Any\n",
    "    ) -> Any:\n",
    "        print(f\"[Run ID: {run_id}] Tool Error: {error}\")\n",
    "\n",
    "    def on_tool_start(\n",
    "        self,\n",
    "        serialized: Dict[str, Any],\n",
    "        input_str: str,\n",
    "        *,\n",
    "        run_id: UUID,\n",
    "        parent_run_id: Optional[UUID] = None,\n",
    "        tags: Optional[List[str]] = None,\n",
    "        metadata: Optional[Dict[str, Any]] = None,\n",
    "        inputs: Optional[Dict[str, Any]] = None,\n",
    "        **kwargs: Any\n",
    "    ) -> Any:\n",
    "        tool_name = serialized.get(\"name\", \"Unnamed Tool\")\n",
    "        print(f\"[Run ID: {run_id}] Tool '{tool_name}' started with input: '{input_str}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "928826e0-91a4-4924-816a-ed0b596e26c0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Run ID: b54cc9f2-6d1a-4d93-b5ef-af7695e8d630] WARNING: Received None for 'serialized' in on_chain_start.\n",
      "[Run ID: b54cc9f2-6d1a-4d93-b5ef-af7695e8d630] INFO: Chain 'Unnamed Chain' started with inputs: {'topic': 'Natural Language Processing', 'text': 'Tell me more about IBM Watson'}\n",
      "[Run ID: e1ca1b72-cea3-408c-8aa6-c565c75194fc] INFO: Chain 'ChatPromptTemplate' started with inputs: {'topic': 'Natural Language Processing', 'text': 'Tell me more about IBM Watson'}\n",
      "[Run ID: e1ca1b72-cea3-408c-8aa6-c565c75194fc] Chain Ended with outputs: messages=[HumanMessage(content='Explain to the user the story of the Natural Language Processing he asked for.', additional_kwargs={}, response_metadata={}), HumanMessage(content='Tell me more about IBM Watson', additional_kwargs={}, response_metadata={})]\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] LLM 'Unnamed LLM' started with prompts: ['Human: Explain to the user the story of the Natural Language Processing he asked for.\\nHuman: Tell me more about IBM Watson']\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token: The\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token:  story\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token:  of\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token:  N\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token: LP\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token:  (\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token: Natural\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token:  Language\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token:  Processing\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token: )\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token:  is\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token:  a\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token:  fascinating\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token:  one\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token:  that\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token:  has\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token:  evolved\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token:  over\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token:  decades\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token: .\n",
      "\n",
      "\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token: **\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token: What\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token:  is\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token:  N\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token: LP\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token: ?\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token: **\n",
      "\n",
      "\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token: N\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token: LP\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token:  is\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token:  a\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token:  sub\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token: field\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token:  of\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token:  artificial\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token:  intelligence\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token:  (\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token: AI\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token: )\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token:  that\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token:  deals\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token:  with\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token:  the\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token:  interaction\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token:  between\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token:  computers\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token:  and\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token:  humans\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token:  in\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token:  natural\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token:  language\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token: .\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token:  It\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token: 's\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token:  a\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token:  branch\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token:  of\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token:  AI\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token:  research\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token:  that\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token:  aims\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token:  to\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token:  enable\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token:  machines\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token:  to\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token:  understand\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token: ,\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token:  interpret\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token: ,\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token:  and\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token:  generate\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token:  human\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token: -like\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token:  language\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token: .\n",
      "\n",
      "\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token: **\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token: Early\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token:  Begin\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token: nings\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token: :\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token: **\n",
      "\n",
      "\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token: The\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token:  concept\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token:  of\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token:  N\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token: LP\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token:  dates\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token:  back\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token:  to\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token:  the\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token:  \n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token: 195\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token: 0\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token: s\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token: ,\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token:  when\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token:  Alan\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token:  Turing\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token:  proposed\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token:  the\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token:  idea\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token:  of\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token:  machine\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token:  translation\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token: .\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token:  However\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token: ,\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token:  it\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token:  wasn\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token: 't\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token:  until\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token:  the\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token:  \n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token: 196\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token: 0\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token: s\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token:  that\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token:  N\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token: LP\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token:  began\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token:  to\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token:  take\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token:  shape\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token:  as\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token:  a\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token:  distinct\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token:  field\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token: .\n",
      "\n",
      "\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token: **\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token: Key\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token:  Mile\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token: stones\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token: :\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token: **\n",
      "\n",
      "\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token: 1\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token: .\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token:  **\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token: Ch\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token: om\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token: sky\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token: 's\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token:  Transformation\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token: al\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token:  Grammar\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token:  (\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token: 195\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token: 7\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token: ):\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token: **\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token:  No\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token: am\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token:  Ch\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token: om\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token: sky\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token:  introduced\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token:  the\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token:  concept\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token:  of\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token:  transformation\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token: al\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token:  grammar\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token: ,\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token:  which\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token:  laid\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token:  the\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token:  foundation\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token:  for\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token:  modern\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token:  N\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token: LP\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token: .\n",
      "\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token: 2\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token: .\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token:  **\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token: Word\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token: Net\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token:  (\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token: 199\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token: 3\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token: ):\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token: **\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token:  A\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token:  large\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token:  lexical\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token:  database\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token:  that\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token:  enabled\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token:  computers\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token:  to\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token:  understand\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token:  word\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token:  relationships\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token:  and\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token:  semantics\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token: .\n",
      "\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token: 3\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token: .\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token:  **\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token: Deep\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token:  Learning\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token:  (\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token: 200\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token: 0\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token: s\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token: ):\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token: **\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token:  The\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token:  resurgence\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token:  of\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token:  deep\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token:  learning\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token:  techniques\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token:  in\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token:  the\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token:  \n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token: 201\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token: 0\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token: s\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token:  revolution\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token: ized\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token:  N\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token: LP\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token: ,\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token:  enabling\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token:  machines\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token:  to\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token:  learn\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token:  complex\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token:  patterns\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token:  in\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token:  language\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token: .\n",
      "\n",
      "\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token: **\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token: IBM\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token:  Watson\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token: :\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token: **\n",
      "\n",
      "\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token: Now\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token: ,\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token:  let\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token: 's\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token:  dive\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token:  into\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token:  IBM\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token:  Watson\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token: !\n",
      "\n",
      "\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token: **\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token: What\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token:  is\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token:  IBM\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token:  Watson\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token: ?\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token: **\n",
      "\n",
      "\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token: IBM\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token:  Watson\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token:  is\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token:  an\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token:  AI\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token:  platform\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token:  that\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token:  uses\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token:  natural\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token:  language\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token:  processing\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token: ,\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token:  machine\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token:  learning\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token: ,\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token:  and\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token:  data\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token:  analytics\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token:  to\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token:  help\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token:  organizations\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token:  make\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token:  better\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token:  decisions\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token: .\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token:  It\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token:  was\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token:  first\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token:  introduced\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token:  in\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token:  \n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token: 201\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token: 1\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token:  as\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token:  a\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token:  question\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token: -\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token: ans\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token: w\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token: ering\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token:  system\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token:  for\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token:  Je\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token: opard\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token: y\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token: !,\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token:  where\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token:  it\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token:  defeated\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token:  two\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token:  human\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token:  contestants\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token: .\n",
      "\n",
      "\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token: **\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token: Key\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token:  Features\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token: :\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token: **\n",
      "\n",
      "\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token: 1\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token: .\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token:  **\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token: Question\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token:  Answer\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token: ing\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token: :**\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token:  IBM\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token:  Watson\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token:  can\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token:  answer\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token:  questions\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token:  based\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token:  on\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token:  a\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token:  vast\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token:  knowledge\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token:  base\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token: ,\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token:  which\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token:  is\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token:  continuously\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token:  updated\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token: .\n",
      "\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token: 2\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token: .\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token:  **\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token: Text\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token:  Analysis\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token: :**\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token:  Watson\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token:  can\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token:  analyze\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token:  large\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token:  amounts\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token:  of\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token:  text\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token:  data\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token:  to\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token:  identify\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token:  patterns\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token: ,\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token:  sentiment\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token: ,\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token:  and\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token:  entities\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token: .\n",
      "\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token: 3\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token: .\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token:  **\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token: Machine\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token:  Learning\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token: :**\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token:  Watson\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token:  uses\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token:  machine\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token:  learning\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token:  algorithms\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token:  to\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token:  learn\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token:  from\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token:  data\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token:  and\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token:  improve\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token:  its\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token:  performance\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token:  over\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token:  time\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token: .\n",
      "\n",
      "\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token: **\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token: Applications\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token: :\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token: **\n",
      "\n",
      "\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token: IBM\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token:  Watson\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token:  has\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token:  been\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token:  applied\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token:  in\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token:  various\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token:  domains\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token: ,\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token:  including\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token: :\n",
      "\n",
      "\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token: 1\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token: .\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token:  **\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token: Health\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token: care\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token: :**\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token:  Analy\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token: zing\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token:  medical\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token:  records\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token:  and\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token:  identifying\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token:  potential\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token:  treatments\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token:  for\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token:  diseases\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token: .\n",
      "\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token: 2\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token: .\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token:  **\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token: Customer\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token:  Service\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token: :**\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token:  Providing\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token:  chat\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token: bots\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token:  with\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token:  intelligent\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token:  customer\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token:  service\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token:  capabilities\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token: .\n",
      "\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token: 3\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token: .\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token:  **\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token: Marketing\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token: :**\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token:  Helping\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token:  companies\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token:  analyze\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token:  customer\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token:  sentiment\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token:  and\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token:  preferences\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token: .\n",
      "\n",
      "\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token: **\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token: Benefits\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token: :\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token: **\n",
      "\n",
      "\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token: 1\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token: .\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token:  **\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token: Improved\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token:  Decision\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token:  Making\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token: :**\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token:  IBM\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token:  Watson\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token:  enables\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token:  organizations\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token:  to\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token:  make\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token:  more\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token:  informed\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token:  decisions\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token:  by\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token:  analyzing\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token:  vast\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token:  amounts\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token:  of\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token:  data\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token: .\n",
      "\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token: 2\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token: .\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token:  **\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token: Increased\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token:  Efficiency\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token: :**\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token:  Watson\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token:  autom\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token: ates\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token:  tasks\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token: ,\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token:  reducing\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token:  manual\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token:  labor\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token:  and\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token:  freeing\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token:  up\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token:  resources\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token:  for\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token:  strategic\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token:  initiatives\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token: .\n",
      "\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token: 3\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token: .\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token:  **\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token: Enh\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token: anced\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token:  Customer\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token:  Experience\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token: :**\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token:  Watson\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token: -powered\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token:  chat\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token: bots\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token:  provide\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token:  personalized\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token:  customer\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token:  service\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token:  and\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token:  improve\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token:  overall\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token:  experience\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token: .\n",
      "\n",
      "\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token: **\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token: In\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token:  Conclusion\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token: :\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token: **\n",
      "\n",
      "\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token: IBM\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token:  Watson\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token:  is\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token:  a\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token:  powerful\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token:  AI\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token:  platform\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token:  that\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token:  harness\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token: es\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token:  the\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token:  power\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token:  of\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token:  natural\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token:  language\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token:  processing\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token:  to\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token:  transform\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token:  industries\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token:  and\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token:  businesses\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token: .\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token:  Its\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token:  applications\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token:  range\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token:  from\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token:  healthcare\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token:  to\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token:  marketing\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token: ,\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token:  making\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token:  it\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token:  an\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token:  essential\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token:  tool\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token:  for\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token:  organizations\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token:  seeking\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token:  to\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token:  stay\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token:  ahead\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token:  in\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token:  the\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token:  digital\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token:  age\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token: .\n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] New LLM Token: \n",
      "[Run ID: 6b7ba8c0-8124-4528-aa1f-bdc1606fd0d6] LLM Ended with response: generations=[[GenerationChunk(text=\"The story of NLP (Natural Language Processing) is a fascinating one that has evolved over decades.\\n\\n**What is NLP?**\\n\\nNLP is a subfield of artificial intelligence (AI) that deals with the interaction between computers and humans in natural language. It's a branch of AI research that aims to enable machines to understand, interpret, and generate human-like language.\\n\\n**Early Beginnings:**\\n\\nThe concept of NLP dates back to the 1950s, when Alan Turing proposed the idea of machine translation. However, it wasn't until the 1960s that NLP began to take shape as a distinct field.\\n\\n**Key Milestones:**\\n\\n1. **Chomsky's Transformational Grammar (1957):** Noam Chomsky introduced the concept of transformational grammar, which laid the foundation for modern NLP.\\n2. **WordNet (1993):** A large lexical database that enabled computers to understand word relationships and semantics.\\n3. **Deep Learning (2000s):** The resurgence of deep learning techniques in the 2010s revolutionized NLP, enabling machines to learn complex patterns in language.\\n\\n**IBM Watson:**\\n\\nNow, let's dive into IBM Watson!\\n\\n**What is IBM Watson?**\\n\\nIBM Watson is an AI platform that uses natural language processing, machine learning, and data analytics to help organizations make better decisions. It was first introduced in 2011 as a question-answering system for Jeopardy!, where it defeated two human contestants.\\n\\n**Key Features:**\\n\\n1. **Question Answering:** IBM Watson can answer questions based on a vast knowledge base, which is continuously updated.\\n2. **Text Analysis:** Watson can analyze large amounts of text data to identify patterns, sentiment, and entities.\\n3. **Machine Learning:** Watson uses machine learning algorithms to learn from data and improve its performance over time.\\n\\n**Applications:**\\n\\nIBM Watson has been applied in various domains, including:\\n\\n1. **Healthcare:** Analyzing medical records and identifying potential treatments for diseases.\\n2. **Customer Service:** Providing chatbots with intelligent customer service capabilities.\\n3. **Marketing:** Helping companies analyze customer sentiment and preferences.\\n\\n**Benefits:**\\n\\n1. **Improved Decision Making:** IBM Watson enables organizations to make more informed decisions by analyzing vast amounts of data.\\n2. **Increased Efficiency:** Watson automates tasks, reducing manual labor and freeing up resources for strategic initiatives.\\n3. **Enhanced Customer Experience:** Watson-powered chatbots provide personalized customer service and improve overall experience.\\n\\n**In Conclusion:**\\n\\nIBM Watson is a powerful AI platform that harnesses the power of natural language processing to transform industries and businesses. Its applications range from healthcare to marketing, making it an essential tool for organizations seeking to stay ahead in the digital age.\", generation_info={'model': 'llama3.2', 'created_at': '2024-10-06T22:00:30.801449793Z', 'response': '', 'done': True, 'done_reason': 'stop', 'context': [128006, 9125, 128007, 271, 38766, 1303, 33025, 2696, 25, 6790, 220, 2366, 18, 271, 128009, 128006, 882, 128007, 271, 35075, 25, 83017, 311, 279, 1217, 279, 3446, 315, 279, 18955, 11688, 29225, 568, 4691, 369, 627, 35075, 25, 25672, 757, 810, 922, 29022, 32580, 128009, 128006, 78191, 128007, 271, 791, 3446, 315, 452, 12852, 320, 55381, 11688, 29225, 8, 374, 264, 27387, 832, 430, 706, 28995, 927, 11026, 382, 334, 3923, 374, 452, 12852, 30, 57277, 45, 12852, 374, 264, 1207, 2630, 315, 21075, 11478, 320, 15836, 8, 430, 12789, 449, 279, 16628, 1990, 19002, 323, 12966, 304, 5933, 4221, 13, 1102, 596, 264, 9046, 315, 15592, 3495, 430, 22262, 311, 7431, 12933, 311, 3619, 11, 14532, 11, 323, 7068, 3823, 12970, 4221, 382, 334, 42298, 19110, 39569, 25, 57277, 791, 7434, 315, 452, 12852, 13003, 1203, 311, 279, 220, 6280, 15, 82, 11, 994, 26349, 95530, 11223, 279, 4623, 315, 5780, 14807, 13, 4452, 11, 433, 5828, 956, 3156, 279, 220, 5162, 15, 82, 430, 452, 12852, 6137, 311, 1935, 6211, 439, 264, 12742, 2115, 382, 334, 1622, 39697, 33610, 25, 57277, 16, 13, 3146, 1163, 316, 27782, 596, 54752, 278, 63077, 320, 6280, 22, 1680, 334, 2360, 309, 921, 316, 27782, 11784, 279, 7434, 315, 18475, 278, 32528, 11, 902, 17551, 279, 16665, 369, 6617, 452, 12852, 627, 17, 13, 3146, 11116, 7099, 320, 2550, 18, 1680, 334, 362, 3544, 78686, 4729, 430, 9147, 19002, 311, 3619, 3492, 12135, 323, 53794, 627, 18, 13, 3146, 34564, 21579, 320, 1049, 15, 82, 1680, 334, 578, 91590, 315, 5655, 6975, 12823, 304, 279, 220, 679, 15, 82, 14110, 1534, 452, 12852, 11, 28462, 12933, 311, 4048, 6485, 12912, 304, 4221, 382, 334, 68838, 32580, 25, 57277, 7184, 11, 1095, 596, 30963, 1139, 29022, 32580, 2268, 334, 3923, 374, 29022, 32580, 30, 57277, 68838, 32580, 374, 459, 15592, 5452, 430, 5829, 5933, 4221, 8863, 11, 5780, 6975, 11, 323, 828, 28975, 311, 1520, 11351, 1304, 2731, 11429, 13, 1102, 574, 1176, 11784, 304, 220, 679, 16, 439, 264, 3488, 12, 598, 86, 4776, 1887, 369, 14465, 33029, 88, 17581, 1405, 433, 24164, 1403, 3823, 75524, 382, 334, 1622, 20289, 25, 57277, 16, 13, 3146, 14924, 22559, 287, 68063, 29022, 32580, 649, 4320, 4860, 3196, 389, 264, 13057, 6677, 2385, 11, 902, 374, 31978, 6177, 627, 17, 13, 3146, 1199, 18825, 68063, 32580, 649, 24564, 3544, 15055, 315, 1495, 828, 311, 10765, 12912, 11, 27065, 11, 323, 15086, 627, 18, 13, 3146, 22333, 21579, 68063, 32580, 5829, 5780, 6975, 26249, 311, 4048, 505, 828, 323, 7417, 1202, 5178, 927, 892, 382, 334, 51459, 25, 57277, 68838, 32580, 706, 1027, 9435, 304, 5370, 31576, 11, 2737, 1473, 16, 13, 3146, 14884, 10727, 68063, 38527, 20994, 6593, 7576, 323, 25607, 4754, 22972, 369, 19338, 627, 17, 13, 3146, 13084, 5475, 68063, 81200, 6369, 63005, 449, 25530, 6130, 2532, 17357, 627, 18, 13, 3146, 68662, 68063, 91801, 5220, 24564, 6130, 27065, 323, 19882, 382, 334, 85423, 25, 57277, 16, 13, 3146, 82210, 41525, 25274, 68063, 29022, 32580, 20682, 11351, 311, 1304, 810, 16369, 11429, 555, 42118, 13057, 15055, 315, 828, 627, 17, 13, 3146, 97941, 67667, 68063, 32580, 5113, 988, 9256, 11, 18189, 11630, 9511, 323, 67817, 709, 5070, 369, 19092, 28271, 627, 18, 13, 3146, 58568, 4979, 12557, 21460, 68063, 32580, 41503, 6369, 63005, 3493, 35649, 6130, 2532, 323, 7417, 8244, 3217, 382, 334, 644, 74977, 25, 57277, 68838, 32580, 374, 264, 8147, 15592, 5452, 430, 33508, 288, 279, 2410, 315, 5933, 4221, 8863, 311, 5276, 19647, 323, 9873, 13, 11699, 8522, 2134, 505, 18985, 311, 8661, 11, 3339, 433, 459, 7718, 5507, 369, 11351, 11125, 311, 4822, 8469, 304, 279, 7528, 4325, 13], 'total_duration': 2774356831, 'load_duration': 15518808, 'prompt_eval_count': 50, 'prompt_eval_duration': 6950000, 'eval_count': 562, 'eval_duration': 2615365000})]] llm_output=None run=None type='LLMResult'\n",
      "[Run ID: ebaa65cb-0b98-4348-8058-827a1a9e5379] WARNING: Received None for 'serialized' in on_chain_start.\n",
      "[Run ID: ebaa65cb-0b98-4348-8058-827a1a9e5379] INFO: Chain 'Unnamed Chain' started with inputs: The story of NLP (Natural Language Processing) is a fascinating one that has evolved over decades.\n",
      "\n",
      "**What is NLP?**\n",
      "\n",
      "NLP is a subfield of artificial intelligence (AI) that deals with the interaction between computers and humans in natural language. It's a branch of AI research that aims to enable machines to understand, interpret, and generate human-like language.\n",
      "\n",
      "**Early Beginnings:**\n",
      "\n",
      "The concept of NLP dates back to the 1950s, when Alan Turing proposed the idea of machine translation. However, it wasn't until the 1960s that NLP began to take shape as a distinct field.\n",
      "\n",
      "**Key Milestones:**\n",
      "\n",
      "1. **Chomsky's Transformational Grammar (1957):** Noam Chomsky introduced the concept of transformational grammar, which laid the foundation for modern NLP.\n",
      "2. **WordNet (1993):** A large lexical database that enabled computers to understand word relationships and semantics.\n",
      "3. **Deep Learning (2000s):** The resurgence of deep learning techniques in the 2010s revolutionized NLP, enabling machines to learn complex patterns in language.\n",
      "\n",
      "**IBM Watson:**\n",
      "\n",
      "Now, let's dive into IBM Watson!\n",
      "\n",
      "**What is IBM Watson?**\n",
      "\n",
      "IBM Watson is an AI platform that uses natural language processing, machine learning, and data analytics to help organizations make better decisions. It was first introduced in 2011 as a question-answering system for Jeopardy!, where it defeated two human contestants.\n",
      "\n",
      "**Key Features:**\n",
      "\n",
      "1. **Question Answering:** IBM Watson can answer questions based on a vast knowledge base, which is continuously updated.\n",
      "2. **Text Analysis:** Watson can analyze large amounts of text data to identify patterns, sentiment, and entities.\n",
      "3. **Machine Learning:** Watson uses machine learning algorithms to learn from data and improve its performance over time.\n",
      "\n",
      "**Applications:**\n",
      "\n",
      "IBM Watson has been applied in various domains, including:\n",
      "\n",
      "1. **Healthcare:** Analyzing medical records and identifying potential treatments for diseases.\n",
      "2. **Customer Service:** Providing chatbots with intelligent customer service capabilities.\n",
      "3. **Marketing:** Helping companies analyze customer sentiment and preferences.\n",
      "\n",
      "**Benefits:**\n",
      "\n",
      "1. **Improved Decision Making:** IBM Watson enables organizations to make more informed decisions by analyzing vast amounts of data.\n",
      "2. **Increased Efficiency:** Watson automates tasks, reducing manual labor and freeing up resources for strategic initiatives.\n",
      "3. **Enhanced Customer Experience:** Watson-powered chatbots provide personalized customer service and improve overall experience.\n",
      "\n",
      "**In Conclusion:**\n",
      "\n",
      "IBM Watson is a powerful AI platform that harnesses the power of natural language processing to transform industries and businesses. Its applications range from healthcare to marketing, making it an essential tool for organizations seeking to stay ahead in the digital age.\n",
      "[Run ID: ebaa65cb-0b98-4348-8058-827a1a9e5379] Chain Ended with outputs: The story of NLP (Natural Language Processing) is a fascinating one that has evolved over decades.\n",
      "\n",
      "**What is NLP?**\n",
      "\n",
      "NLP is a subfield of artificial intelligence (AI) that deals with the interaction between computers and humans in natural language. It's a branch of AI research that aims to enable machines to understand, interpret, and generate human-like language.\n",
      "\n",
      "**Early Beginnings:**\n",
      "\n",
      "The concept of NLP dates back to the 1950s, when Alan Turing proposed the idea of machine translation. However, it wasn't until the 1960s that NLP began to take shape as a distinct field.\n",
      "\n",
      "**Key Milestones:**\n",
      "\n",
      "1. **Chomsky's Transformational Grammar (1957):** Noam Chomsky introduced the concept of transformational grammar, which laid the foundation for modern NLP.\n",
      "2. **WordNet (1993):** A large lexical database that enabled computers to understand word relationships and semantics.\n",
      "3. **Deep Learning (2000s):** The resurgence of deep learning techniques in the 2010s revolutionized NLP, enabling machines to learn complex patterns in language.\n",
      "\n",
      "**IBM Watson:**\n",
      "\n",
      "Now, let's dive into IBM Watson!\n",
      "\n",
      "**What is IBM Watson?**\n",
      "\n",
      "IBM Watson is an AI platform that uses natural language processing, machine learning, and data analytics to help organizations make better decisions. It was first introduced in 2011 as a question-answering system for Jeopardy!, where it defeated two human contestants.\n",
      "\n",
      "**Key Features:**\n",
      "\n",
      "1. **Question Answering:** IBM Watson can answer questions based on a vast knowledge base, which is continuously updated.\n",
      "2. **Text Analysis:** Watson can analyze large amounts of text data to identify patterns, sentiment, and entities.\n",
      "3. **Machine Learning:** Watson uses machine learning algorithms to learn from data and improve its performance over time.\n",
      "\n",
      "**Applications:**\n",
      "\n",
      "IBM Watson has been applied in various domains, including:\n",
      "\n",
      "1. **Healthcare:** Analyzing medical records and identifying potential treatments for diseases.\n",
      "2. **Customer Service:** Providing chatbots with intelligent customer service capabilities.\n",
      "3. **Marketing:** Helping companies analyze customer sentiment and preferences.\n",
      "\n",
      "**Benefits:**\n",
      "\n",
      "1. **Improved Decision Making:** IBM Watson enables organizations to make more informed decisions by analyzing vast amounts of data.\n",
      "2. **Increased Efficiency:** Watson automates tasks, reducing manual labor and freeing up resources for strategic initiatives.\n",
      "3. **Enhanced Customer Experience:** Watson-powered chatbots provide personalized customer service and improve overall experience.\n",
      "\n",
      "**In Conclusion:**\n",
      "\n",
      "IBM Watson is a powerful AI platform that harnesses the power of natural language processing to transform industries and businesses. Its applications range from healthcare to marketing, making it an essential tool for organizations seeking to stay ahead in the digital age.\n",
      "[Run ID: b54cc9f2-6d1a-4d93-b5ef-af7695e8d630] Chain Ended with outputs: The story of NLP (Natural Language Processing) is a fascinating one that has evolved over decades.\n",
      "\n",
      "**What is NLP?**\n",
      "\n",
      "NLP is a subfield of artificial intelligence (AI) that deals with the interaction between computers and humans in natural language. It's a branch of AI research that aims to enable machines to understand, interpret, and generate human-like language.\n",
      "\n",
      "**Early Beginnings:**\n",
      "\n",
      "The concept of NLP dates back to the 1950s, when Alan Turing proposed the idea of machine translation. However, it wasn't until the 1960s that NLP began to take shape as a distinct field.\n",
      "\n",
      "**Key Milestones:**\n",
      "\n",
      "1. **Chomsky's Transformational Grammar (1957):** Noam Chomsky introduced the concept of transformational grammar, which laid the foundation for modern NLP.\n",
      "2. **WordNet (1993):** A large lexical database that enabled computers to understand word relationships and semantics.\n",
      "3. **Deep Learning (2000s):** The resurgence of deep learning techniques in the 2010s revolutionized NLP, enabling machines to learn complex patterns in language.\n",
      "\n",
      "**IBM Watson:**\n",
      "\n",
      "Now, let's dive into IBM Watson!\n",
      "\n",
      "**What is IBM Watson?**\n",
      "\n",
      "IBM Watson is an AI platform that uses natural language processing, machine learning, and data analytics to help organizations make better decisions. It was first introduced in 2011 as a question-answering system for Jeopardy!, where it defeated two human contestants.\n",
      "\n",
      "**Key Features:**\n",
      "\n",
      "1. **Question Answering:** IBM Watson can answer questions based on a vast knowledge base, which is continuously updated.\n",
      "2. **Text Analysis:** Watson can analyze large amounts of text data to identify patterns, sentiment, and entities.\n",
      "3. **Machine Learning:** Watson uses machine learning algorithms to learn from data and improve its performance over time.\n",
      "\n",
      "**Applications:**\n",
      "\n",
      "IBM Watson has been applied in various domains, including:\n",
      "\n",
      "1. **Healthcare:** Analyzing medical records and identifying potential treatments for diseases.\n",
      "2. **Customer Service:** Providing chatbots with intelligent customer service capabilities.\n",
      "3. **Marketing:** Helping companies analyze customer sentiment and preferences.\n",
      "\n",
      "**Benefits:**\n",
      "\n",
      "1. **Improved Decision Making:** IBM Watson enables organizations to make more informed decisions by analyzing vast amounts of data.\n",
      "2. **Increased Efficiency:** Watson automates tasks, reducing manual labor and freeing up resources for strategic initiatives.\n",
      "3. **Enhanced Customer Experience:** Watson-powered chatbots provide personalized customer service and improve overall experience.\n",
      "\n",
      "**In Conclusion:**\n",
      "\n",
      "IBM Watson is a powerful AI platform that harnesses the power of natural language processing to transform industries and businesses. Its applications range from healthcare to marketing, making it an essential tool for organizations seeking to stay ahead in the digital age.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"The story of NLP (Natural Language Processing) is a fascinating one that has evolved over decades.\\n\\n**What is NLP?**\\n\\nNLP is a subfield of artificial intelligence (AI) that deals with the interaction between computers and humans in natural language. It's a branch of AI research that aims to enable machines to understand, interpret, and generate human-like language.\\n\\n**Early Beginnings:**\\n\\nThe concept of NLP dates back to the 1950s, when Alan Turing proposed the idea of machine translation. However, it wasn't until the 1960s that NLP began to take shape as a distinct field.\\n\\n**Key Milestones:**\\n\\n1. **Chomsky's Transformational Grammar (1957):** Noam Chomsky introduced the concept of transformational grammar, which laid the foundation for modern NLP.\\n2. **WordNet (1993):** A large lexical database that enabled computers to understand word relationships and semantics.\\n3. **Deep Learning (2000s):** The resurgence of deep learning techniques in the 2010s revolutionized NLP, enabling machines to learn complex patterns in language.\\n\\n**IBM Watson:**\\n\\nNow, let's dive into IBM Watson!\\n\\n**What is IBM Watson?**\\n\\nIBM Watson is an AI platform that uses natural language processing, machine learning, and data analytics to help organizations make better decisions. It was first introduced in 2011 as a question-answering system for Jeopardy!, where it defeated two human contestants.\\n\\n**Key Features:**\\n\\n1. **Question Answering:** IBM Watson can answer questions based on a vast knowledge base, which is continuously updated.\\n2. **Text Analysis:** Watson can analyze large amounts of text data to identify patterns, sentiment, and entities.\\n3. **Machine Learning:** Watson uses machine learning algorithms to learn from data and improve its performance over time.\\n\\n**Applications:**\\n\\nIBM Watson has been applied in various domains, including:\\n\\n1. **Healthcare:** Analyzing medical records and identifying potential treatments for diseases.\\n2. **Customer Service:** Providing chatbots with intelligent customer service capabilities.\\n3. **Marketing:** Helping companies analyze customer sentiment and preferences.\\n\\n**Benefits:**\\n\\n1. **Improved Decision Making:** IBM Watson enables organizations to make more informed decisions by analyzing vast amounts of data.\\n2. **Increased Efficiency:** Watson automates tasks, reducing manual labor and freeing up resources for strategic initiatives.\\n3. **Enhanced Customer Experience:** Watson-powered chatbots provide personalized customer service and improve overall experience.\\n\\n**In Conclusion:**\\n\\nIBM Watson is a powerful AI platform that harnesses the power of natural language processing to transform industries and businesses. Its applications range from healthcare to marketing, making it an essential tool for organizations seeking to stay ahead in the digital age.\""
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize the callback handler\n",
    "callbacks = [LoggingHandler()]\n",
    "\n",
    "# Invoke the chain with input and callback configuration\n",
    "simplechain.invoke(\n",
    "    {\"topic\": \"Natural Language Processing\", \"text\": \"Tell me more about IBM Watson\"},\n",
    "    config={\"callbacks\": callbacks}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "906e1c0d-ce14-4b03-8dd4-c59d98a41871",
   "metadata": {},
   "source": [
    "# Chat interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc7534af-918f-42e1-b1fc-2350ed141d07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the ChatOllama class from the langchain_ollama module\n",
    "from langchain_ollama import ChatOllama\n",
    "\n",
    "# Initializing a language model (LLM) using the ChatOllama class\n",
    "# max_tokens limits the response to 1024 tokens\n",
    "# temperature is set to 0, meaning deterministic responses with no randomness\n",
    "llm = ChatOllama(model=\"llama3.2\", max_tokens=1024, temperature=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2888361-b51f-4cc7-8a73-26bca0e3801b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Annotated from typing to allow advanced type annotations\n",
    "from typing import Annotated\n",
    "# Importing TypedDict from typing_extensions to define a dictionary with fixed keys and value types\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "# Importing AnyMessage from langchain_core.messages to define a general message type\n",
    "from langchain_core.messages import AnyMessage\n",
    "\n",
    "# Importing necessary components from langgraph to build a state graph\n",
    "from langgraph.graph import StateGraph, START, END  # START and END mark the flow of states in the graph\n",
    "from langgraph.graph.message import add_messages  # add_messages defines how messages should be added to the state\n",
    "\n",
    "# Defining the State class as a TypedDict\n",
    "# This class represents the structure of the state, with one key: \"messages\"\n",
    "class State(TypedDict):\n",
    "    # The \"messages\" key stores a list of AnyMessage instances\n",
    "    # The Annotated type allows the `add_messages` function to handle how messages are updated\n",
    "    # In this case, `add_messages` appends new messages to the existing list\n",
    "    messages: Annotated[list[AnyMessage], add_messages]\n",
    "\n",
    "# Creating an instance of StateGraph using the defined State structure\n",
    "# This graph will manage the state transitions, where each state holds the messages\n",
    "graph_builder = StateGraph(State)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ff6b3c0-400c-4206-afa3-fc96474e8146",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Defining the chatbot function which takes the current state as input\n",
    "# The state is expected to be of type \"State\", containing a list of messages\n",
    "def chatbot(state: State):\n",
    "    # The function returns a dictionary with the key \"messages\"\n",
    "    # It invokes the language model (llm) on the list of messages in the current state\n",
    "    # The llm.invoke() method generates a response based on the input messages\n",
    "    return {\"messages\": [llm.invoke(state[\"messages\"])]}\n",
    "\n",
    "# Adding an edge to the graph from the START node to the \"chatbot\" node\n",
    "# This signifies that the process starts at the START node and moves to the \"chatbot\" node\n",
    "graph_builder.add_edge(START, \"chatbot\")\n",
    "\n",
    "# Adding the \"chatbot\" node to the graph, which points to the chatbot function\n",
    "# Whenever this node is used, the chatbot function will be called\n",
    "graph_builder.add_node(\"chatbot\", chatbot)\n",
    "\n",
    "# Adding an edge from the \"chatbot\" node to the END node\n",
    "# This means that once the \"chatbot\" function is executed, the process moves to the END node, signaling completion\n",
    "graph_builder.add_edge(\"chatbot\", END)\n",
    "\n",
    "# Compiling the graph to make it ready for execution\n",
    "# This graph consists of nodes and edges, representing the flow of state transitions and function calls\n",
    "graph = graph_builder.compile()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29a19b31-1862-4b9d-961a-9e2c741b2d7c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "display(Image(graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f31255c3-8def-4bad-bff0-511ea94f2149",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing AIMessage and HumanMessage to represent different types of messages\n",
    "from langchain_core.messages import AIMessage, HumanMessage\n",
    "\n",
    "# Defining a function to send user input to the chatbot and process responses\n",
    "def send_msg(user_input: str):\n",
    "    # Creating a dictionary with a \"messages\" key containing a list of HumanMessage objects\n",
    "    # The content of the HumanMessage is set to the user's input\n",
    "    messages = {\"messages\": [HumanMessage(content=user_input)]}\n",
    "    \n",
    "    # Streaming events from the graph by providing the user messages as input\n",
    "    for event in graph.stream(input=messages):\n",
    "        # Looping through the event's values (responses generated by the assistant)\n",
    "        for value in event.values():\n",
    "            # Printing the last message in the list of responses from the assistant\n",
    "            print(\"Assistant:\", value[\"messages\"][-1].content)\n",
    "\n",
    "# A continuous loop to interact with the chatbot\n",
    "while True:\n",
    "    try:\n",
    "        # Asking for user input via the console\n",
    "        user_input = input(\"User: \")\n",
    "        # Checking if the user wants to quit by typing \"quit\", \"exit\", or \"q\"\n",
    "        if user_input.lower() in [\"quit\", \"exit\", \"q\"]:\n",
    "            print(\"Goodbye!\")\n",
    "            break  # Exiting the loop if the user wants to quit\n",
    "\n",
    "        # Sending the user input to the send_msg function to get a response from the chatbot\n",
    "        send_msg(user_input)\n",
    "\n",
    "    except:\n",
    "        # Fallback behavior if input() is not available (e.g., in some environments or for testing)\n",
    "        # In this case, the user input is hardcoded to a specific question\n",
    "        user_input = \"What do you know about LangGraph?\"\n",
    "        print(\"User: \" + user_input)\n",
    "        # Sending the hardcoded input to the chatbot\n",
    "        send_msg(user_input)\n",
    "        break  # Ending the loop after this fallback interaction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d055eb3-d405-4981-8d25-eb58322f3ead",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
