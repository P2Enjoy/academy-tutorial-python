# Checklist des bonnes pratiques pour l'ing√©nierie de prompt applicable √† tous les mod√®les de langage bas√©s sur une architecture d√©codeur, comme GPT, BERT (utilis√© en mode d√©codeur) ou d'autres mod√®les similaires :

---

üîß **1. Utilisez le mod√®le le plus performant et le plus r√©cent disponible**

Les mod√®les r√©cents sont g√©n√©ralement mieux entra√Æn√©s, plus polyvalents et souvent plus efficaces en termes de g√©n√©ration. Que vous utilisiez GPT, T5 en mode d√©codeur, ou un autre mod√®le de langage, les versions les plus r√©centes offrent des performances optimis√©es, r√©duisent les biais et sont plus adapt√©es aux t√¢ches complexes. V√©rifiez r√©guli√®rement les mises √† jour et choisissez le mod√®le qui correspond le mieux √† votre t√¢che (pr√©cision vs cr√©ativit√©, rapidit√© vs qualit√©, etc.).

üîß **2. Placez les instructions au d√©but du prompt et utilisez des s√©parateurs pour structurer le contexte**

Les LLMs bas√©s sur une architecture d√©codeur, comme GPT, se comportent mieux si les instructions sont claires et structur√©es d√®s le d√©but. Utilisez des balises comme `###`, `"""` ou autres s√©parateurs pour distinguer les instructions du texte ou du contexte √† traiter. Cela aide √† mieux d√©limiter la partie "directive" de la partie "informationnelle".

Exemple :

```
R√©sum√© du texte ci-dessous en une liste √† puces des points les plus importants.

Texte : """
{votre texte ici}
"""
```

Cela clarifie l‚Äôinstruction pour le mod√®le et limite les erreurs d‚Äôinterpr√©tation.

üîß **3. Soyez aussi pr√©cis, descriptif et d√©taill√© que possible sur le contexte, le r√©sultat, la longueur, le format, le style, etc.**

Plus vous √™tes pr√©cis dans vos consignes, mieux le mod√®le comprendra ce qui est attendu. Cela est valable pour tous les LLMs, peu importe leur architecture. Ne laissez pas de place √† l‚Äôinterpr√©tation si vous avez des attentes claires en mati√®re de style ou de format.

Exemple :

Moins efficace ‚ùå :
```
√âcris un po√®me sur l'intelligence artificielle.
```

Mieux ‚úÖ :
```
√âcris un po√®me inspirant sur l'intelligence artificielle en te concentrant sur les progr√®s r√©cents dans les mod√®les de traitement du langage naturel, dans le style de Victor Hugo.
```

üîß **4. Utilisez des exemples concrets pour formater la sortie**

Les mod√®les de langage sont souvent plus efficaces lorsqu'ils re√ßoivent un exemple clair du format de sortie attendu. Cela est particuli√®rement utile pour les t√¢ches complexes comme l'extraction d'entit√©s, la g√©n√©ration de rapports ou la structuration des donn√©es. Montrer au mod√®le un exemple du format permet non seulement d‚Äôobtenir des r√©sultats plus coh√©rents, mais aussi d'am√©liorer la qualit√© du traitement, surtout dans des t√¢ches r√©p√©titives.

Exemple :

Moins efficace ‚ùå :
```
Extraire les entit√©s mentionn√©es dans le texte ci-dessous.
```

Mieux ‚úÖ :
```
Extraire les entit√©s importantes mentionn√©es dans le texte ci-dessous. Premi√®rement, extraire tous les noms d‚Äôentreprises, ensuite les noms de personnes, puis les sujets sp√©cifiques, et enfin les th√®mes g√©n√©raux.

Format souhait√© :
Noms d'entreprises : <liste_s√©par√©e_par_des_virgules>
Noms de personnes : -||-
Sujets sp√©cifiques : -||-
Th√®mes g√©n√©raux : -||-

Texte : {votre texte ici}
```

üîß **5. Approche graduelle : z√©ro-shot, few-shot, puis fine-tuning si n√©cessaire**

- **Z√©ro-shot** : Essayez de commencer sans fournir d‚Äôexemple pour voir comment le mod√®le se comporte uniquement avec l‚Äôinstruction.
  
- **Few-shot** : Si le z√©ro-shot n‚Äôest pas concluant, fournissez quelques exemples. Cela aide √† ancrer le mod√®le dans le type de r√©ponse attendu. Dans les LLMs bas√©s sur des d√©codeurs, cela est particuli√®rement efficace pour ajuster le style ou le format de la r√©ponse.
  
- **Fine-tuning** : En dernier recours, lorsque ni le z√©ro-shot ni le few-shot ne suffisent √† obtenir des r√©sultats satisfaisants, le fine-tuning du mod√®le sur des jeux de donn√©es sp√©cifiques peut s'av√©rer n√©cessaire.

Exemple en few-shot :
```
Extrait les mots-cl√©s des textes correspondants ci-dessous.

Texte 1 : OpenAI propose une API pour int√©grer des mod√®les de traitement du langage naturel dans les applications web.
Mots-cl√©s 1 : OpenAI, API, traitement du langage naturel, applications web
##
Texte 2 : {votre texte ici}
Mots-cl√©s 2 :
```

üîß **6. √âvitez les descriptions vagues et les termes impr√©cis**

Les descriptions vagues m√®nent √† des r√©sultats incertains. Que ce soit pour GPT ou pour tout autre LLM, il est crucial de fournir des directives claires, mesurables et sp√©cifiques.

Moins efficace ‚ùå :
```
Fais une description du produit en quelques phrases.
```

Mieux ‚úÖ :
```
√âcris une description de 3 √† 5 phrases pour ce produit, mettant en avant ses avantages pour les utilisateurs d√©butants.
```

üîß **7. Donnez des instructions claires au lieu de seulement interdire des actions**

Au lieu de dire seulement ce qu‚Äôil ne faut pas faire, fournissez une alternative concr√®te. Cela r√©duit les erreurs et am√©liore la pertinence de la r√©ponse.

Moins efficace ‚ùå :
```
Ne demande pas de mot de passe ni d‚Äôinformations personnelles.
```

Mieux ‚úÖ :
```
L‚Äôagent doit diagnostiquer le probl√®me et sugg√©rer une solution sans demander de donn√©es personnelles (comme le mot de passe). R√©f√©rez plut√¥t l‚Äôutilisateur √† l'article d‚Äôaide www.exemple.com/aide.
```

üîß **8. Utilisez des indices pour guider le mod√®le dans la g√©n√©ration de code**

Les mod√®les bas√©s sur des architectures d√©codeur, notamment GPT, ont besoin de ¬´ mots d‚Äôaccroche ¬ª pour comprendre dans quel langage ou dans quel format g√©n√©rer une r√©ponse, particuli√®rement pour des t√¢ches techniques comme la g√©n√©ration de code. Utilisez des mots-cl√©s comme "import" pour Python ou "SELECT" pour SQL pour d√©marrer correctement la g√©n√©ration.

Exemple pour Python :
```
# √âcrire une fonction simple en Python qui :
# 1. Demande un nombre en miles
# 2. Convertit les miles en kilom√®tres

import
```

üîß **9. Exploitez les fonctionnalit√©s avanc√©es des LLMs comme "Generate Anything"**

Certains LLMs (comme GPT) proposent des outils int√©gr√©s permettant de g√©n√©rer des suggestions de prompts bas√©es sur des t√¢ches d√©finies. Utiliser ces fonctionnalit√©s peut simplifier le processus d‚Äôing√©nierie de prompt en vous sugg√©rant des formulations optimis√©es.

---

### **Param√®tres √† ajuster pour des r√©sultats optimaux**

Lorsque vous travaillez avec des LLMs, vous pouvez ajuster certains param√®tres pour affiner la g√©n√©ration :

- **Mod√®le** : Utilisez un mod√®le plus performant (plus r√©cent et plus lourd) pour des t√¢ches plus complexes.
- **Temp√©rature** : Modifiez la temp√©rature pour ajuster la cr√©ativit√© de la r√©ponse. Une temp√©rature √©lev√©e favorise la cr√©ativit√© (0,7-1,0), tandis qu'une temp√©rature basse (0,0-0,3) est id√©ale pour les t√¢ches factuelles et pr√©cises.
- **Max_tokens** : Fixez une limite de tokens pour la g√©n√©ration de texte, en fonction du type de r√©ponse attendue.
- **Stop** : D√©finissez des s√©quences d‚Äôarr√™t pour contr√¥ler quand le mod√®le doit arr√™ter la g√©n√©ration de texte.

---

Ces bonnes pratiques sont applicables √† tout mod√®le de langage bas√© sur une architecture de d√©codeur, en incluant les variantes open-source (comme GPT-J ou GPT-Neo), et permettent de maximiser la pertinence et la qualit√© des r√©ponses g√©n√©r√©es. 
